"""
EssentiaX Streamlit Dashboard - Main Application
==============================================
Advanced EDA Dashboard for Data Scientists

Features:
- Smart data upload and preview
- Advanced statistical analysis
- Interactive visualizations
- AI-powered insights and recommendations
- Big data handling (1GB+ datasets)
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
import sys
import time
import io
from typing import Optional, Dict, Any

# Configure Streamlit page
st.set_page_config(
    page_title="EssentiaX - Advanced EDA Dashboard",
    page_icon="üß†",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Add custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 2rem;
    }
    
    .metric-card {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        border-left: 4px solid #667eea;
    }
    
    .status-success {
        color: #28a745;
        font-weight: bold;
    }
    
    .status-warning {
        color: #ffc107;
        font-weight: bold;
    }
    
    .status-error {
        color: #dc3545;
        font-weight: bold;
    }
    
    .sidebar-info {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Add EssentiaX modules to path
sys.path.append(str(Path(__file__).parent.parent))

# Import EssentiaX modules
try:
    from essentiax.io.smart_read import smart_read
    from essentiax.eda.smart_eda import smart_eda
    from essentiax.cleaning.smart_clean_enhanced import smart_clean
    ESSENTIAX_AVAILABLE = True
except ImportError as e:
    st.error(f"EssentiaX modules not available: {e}")
    ESSENTIAX_AVAILABLE = False

# Import Streamlit app utilities
try:
    from utils.data_handler import SmartDataHandler, get_memory_usage
    DATA_HANDLER_AVAILABLE = True
except ImportError as e:
    st.error(f"Data handler not available: {e}")
    DATA_HANDLER_AVAILABLE = False
    # Fallback class
    class SmartDataHandler:
        def __init__(self):
            pass
        def create_smart_sample(self, df, target_size=50000, target_col=None):
            if len(df) > target_size:
                return df.sample(n=target_size, random_state=42), {'sampling_method': 'random'}
            return df, {'sampling_method': 'no_sampling'}
        def progressive_data_loader(self, file_path, initial_rows=1000):
            df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)
            return df.head(initial_rows), {'total_rows': len(df)}
    
    def get_memory_usage():
        return {'rss_mb': 0, 'percent': 0}

# Initialize session state
if 'data' not in st.session_state:
    st.session_state.data = None
if 'eda_results' not in st.session_state:
    st.session_state.eda_results = None
if 'data_handler' not in st.session_state:
    st.session_state.data_handler = SmartDataHandler() if DATA_HANDLER_AVAILABLE else SmartDataHandler()
if 'analysis_history' not in st.session_state:
    st.session_state.analysis_history = []


def main():
    """Main Streamlit application"""
    
    # Header
    st.markdown('<h1 class="main-header">üß† EssentiaX Advanced EDA Dashboard</h1>', unsafe_allow_html=True)
    
    # Sidebar
    with st.sidebar:
        st.markdown("## üöÄ Navigation")
        
        # Navigation menu
        page = st.selectbox(
            "Choose Analysis Mode",
            [
                "üè† Home & Data Upload",
                "üìä Quick EDA Overview", 
                "üî¨ Advanced Statistical Analysis",
                "üìà Interactive Visualizations",
                "ü§ñ AI Insights & Recommendations",
                "üìã Export & Reports"
            ]
        )
        
        st.markdown("---")
        
        # System status
        st.markdown("## üìä System Status")
        if ESSENTIAX_AVAILABLE:
            st.markdown('<p class="status-success">‚úÖ EssentiaX Loaded</p>', unsafe_allow_html=True)
        else:
            st.markdown('<p class="status-error">‚ùå EssentiaX Not Available</p>', unsafe_allow_html=True)
        
        if DATA_HANDLER_AVAILABLE:
            st.markdown('<p class="status-success">‚úÖ Data Handler Loaded</p>', unsafe_allow_html=True)
        else:
            st.markdown('<p class="status-warning">‚ö†Ô∏è Using Fallback Data Handler</p>', unsafe_allow_html=True)
        
        # Memory usage
        try:
            memory_stats = get_memory_usage()
            st.metric("Memory Usage", f"{memory_stats['rss_mb']:.1f} MB", f"{memory_stats['percent']:.1f}%")
        except:
            st.metric("Memory Usage", "N/A")
        
        # Dataset info
        if st.session_state.data is not None:
            st.markdown("## üìã Current Dataset")
            df = st.session_state.data
            st.metric("Rows", f"{len(df):,}")
            st.metric("Columns", f"{len(df.columns)}")
            st.metric("Memory", f"{df.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
        
        st.markdown("---")
        
        # Quick actions
        st.markdown("## ‚ö° Quick Actions")
        if st.button("üîÑ Clear All Data"):
            st.session_state.data = None
            st.session_state.eda_results = None
            st.session_state.analysis_history = []
            st.success("All data cleared!")
            st.experimental_rerun()
        
        if st.session_state.data is not None:
            if st.button("üìä Quick EDA"):
                with st.spinner("Running Quick EDA..."):
                    try:
                        results = smart_eda(
                            st.session_state.data,
                            mode='console',
                            show_visualizations=False,
                            sample_size=10000
                        )
                        st.session_state.eda_results = results
                        st.success("Quick EDA completed!")
                    except Exception as e:
                        st.error(f"EDA failed: {str(e)}")
    
    # Main content based on selected page
    if page == "üè† Home & Data Upload":
        show_home_page()
    elif page == "üìä Quick EDA Overview":
        show_eda_overview()
    elif page == "üî¨ Advanced Statistical Analysis":
        show_advanced_stats()
    elif page == "üìà Interactive Visualizations":
        show_visualizations()
    elif page == "ü§ñ AI Insights & Recommendations":
        show_ai_insights()
    elif page == "üìã Export & Reports":
        show_export_reports()


def show_home_page():
    """Home page with data upload functionality"""
    
    st.markdown("## üè† Welcome to EssentiaX Advanced EDA")
    
    # Introduction
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        ### üéØ What is EssentiaX?
        
        EssentiaX is an advanced Exploratory Data Analysis (EDA) platform designed for data scientists and analysts. 
        It provides:
        
        - **üöÄ Smart Data Handling**: Efficiently process datasets up to 1GB+
        - **üìä Advanced Statistics**: 15+ statistical tests with AI interpretations
        - **üé® Interactive Visualizations**: 20+ plot types optimized for big data
        - **ü§ñ AI-Powered Insights**: Actionable recommendations and interpretations
        - **‚ö° High Performance**: Smart sampling and memory optimization
        
        ### üî• Key Features
        - Handles CSV, Excel, and other formats
        - Real-time memory monitoring
        - Progressive data loading
        - Advanced outlier detection
        - Statistical significance testing
        - Business impact insights
        """)
    
    with col2:
        st.markdown("""
        ### üìà Supported Analysis
        
        **Statistical Tests:**
        - Normality testing
        - Correlation analysis
        - Hypothesis testing
        - Outlier detection
        
        **Visualizations:**
        - Distribution plots
        - Correlation heatmaps
        - Diagnostic plots
        - Interactive charts
        
        **AI Insights:**
        - Data quality scoring
        - Model recommendations
        - Feature engineering tips
        - Business interpretations
        """)
    
    st.markdown("---")
    
    # Data Upload Section
    st.markdown("## üìÅ Data Upload")
    
    upload_method = st.radio(
        "Choose upload method:",
        ["üìé File Upload", "üîó URL/Path", "üé≤ Sample Dataset"]
    )
    
    if upload_method == "üìé File Upload":
        show_file_upload()
    elif upload_method == "üîó URL/Path":
        show_url_upload()
    elif upload_method == "üé≤ Sample Dataset":
        show_sample_datasets()
    
    # Data Preview
    if st.session_state.data is not None:
        show_data_preview()


def show_file_upload():
    """File upload interface"""
    
    uploaded_file = st.file_uploader(
        "Choose a file",
        type=['csv', 'xlsx', 'xls'],
        help="Supported formats: CSV, Excel (.xlsx, .xls). Maximum size: 200MB"
    )
    
    if uploaded_file is not None:
        # File info
        file_size = len(uploaded_file.getvalue()) / 1024 / 1024  # MB
        st.info(f"üìÑ File: {uploaded_file.name} ({file_size:.1f} MB)")
        
        # Load data
        if st.button("üöÄ Load Data"):
            with st.spinner("Loading data..."):
                try:
                    # Save uploaded file temporarily
                    temp_path = f"temp_{uploaded_file.name}"
                    with open(temp_path, "wb") as f:
                        f.write(uploaded_file.getvalue())
                    
                    # Use progressive loading for large files
                    if file_size > 50:
                        initial_df, loader_info = st.session_state.data_handler.progressive_data_loader(
                            temp_path, initial_rows=5000
                        )
                        st.session_state.data = initial_df
                        st.warning(f"Large file detected. Loaded first {len(initial_df):,} rows for preview. Total rows: {loader_info.get('total_rows', 'Unknown'):,}")
                    else:
                        # Use smart_read for smaller files
                        if ESSENTIAX_AVAILABLE:
                            df = smart_read(temp_path)
                        else:
                            if uploaded_file.name.endswith('.csv'):
                                df = pd.read_csv(temp_path)
                            else:
                                df = pd.read_excel(temp_path)
                        st.session_state.data = df
                    
                    # Clean up temp file
                    import os
                    if os.path.exists(temp_path):
                        os.remove(temp_path)
                    
                    st.success(f"‚úÖ Data loaded successfully! Shape: {st.session_state.data.shape}")
                    st.experimental_rerun()
                    
                except Exception as e:
                    st.error(f"‚ùå Error loading data: {str(e)}")


def show_url_upload():
    """URL/Path upload interface"""
    
    data_source = st.text_input(
        "Enter file path or URL:",
        placeholder="https://example.com/data.csv or /path/to/file.csv",
        help="Supports local file paths and HTTP/HTTPS URLs"
    )
    
    if data_source and st.button("üåê Load from Source"):
        with st.spinner("Loading data from source..."):
            try:
                if ESSENTIAX_AVAILABLE:
                    df = smart_read(data_source)
                else:
                    if data_source.endswith('.csv'):
                        df = pd.read_csv(data_source)
                    else:
                        df = pd.read_excel(data_source)
                
                st.session_state.data = df
                st.success(f"‚úÖ Data loaded successfully! Shape: {df.shape}")
                st.experimental_rerun()
                
            except Exception as e:
                st.error(f"‚ùå Error loading data: {str(e)}")


def show_sample_datasets():
    """Sample dataset selection"""
    
    st.markdown("### üé≤ Choose a Sample Dataset")
    
    sample_choice = st.selectbox(
        "Select sample dataset:",
        [
            "üè† Housing Prices (Regression)",
            "üå∏ Iris Classification", 
            "üí≥ Credit Card Fraud (Imbalanced)",
            "üìä Sales Data (Time Series)",
            "üß¨ Gene Expression (High Dimensional)"
        ]
    )
    
    if st.button("üì• Load Sample Dataset"):
        with st.spinner("Generating sample dataset..."):
            try:
                df = generate_sample_dataset(sample_choice)
                st.session_state.data = df
                st.success(f"‚úÖ Sample dataset loaded! Shape: {df.shape}")
                st.experimental_rerun()
            except Exception as e:
                st.error(f"‚ùå Error generating sample dataset: {str(e)}")


def generate_sample_dataset(choice: str) -> pd.DataFrame:
    """Generate sample datasets for testing"""
    
    np.random.seed(42)
    
    if "Housing" in choice:
        n = 1000
        df = pd.DataFrame({
            'sqft': np.random.normal(2000, 500, n),
            'bedrooms': np.random.choice([2, 3, 4, 5], n, p=[0.2, 0.4, 0.3, 0.1]),
            'bathrooms': np.random.choice([1, 2, 3, 4], n, p=[0.1, 0.4, 0.4, 0.1]),
            'age': np.random.exponential(10, n),
            'location': np.random.choice(['Urban', 'Suburban', 'Rural'], n, p=[0.5, 0.4, 0.1]),
            'price': None
        })
        # Create realistic price based on features
        df['price'] = (df['sqft'] * 150 + df['bedrooms'] * 10000 + 
                      df['bathrooms'] * 5000 - df['age'] * 1000 + 
                      np.random.normal(0, 20000, n))
        df.loc[df['location'] == 'Urban', 'price'] *= 1.3
        df.loc[df['location'] == 'Rural', 'price'] *= 0.8
        
    elif "Iris" in choice:
        from sklearn.datasets import load_iris
        iris = load_iris()
        df = pd.DataFrame(iris.data, columns=iris.feature_names)
        df['species'] = iris.target_names[iris.target]
        
    elif "Credit" in choice:
        n = 5000
        df = pd.DataFrame({
            'amount': np.random.lognormal(6, 1, n),
            'merchant_category': np.random.choice(['grocery', 'gas', 'restaurant', 'retail', 'online'], n),
            'hour': np.random.choice(range(24), n),
            'day_of_week': np.random.choice(range(7), n),
            'customer_age': np.random.normal(40, 15, n),
            'account_balance': np.random.lognormal(8, 1, n),
            'is_fraud': np.random.choice([0, 1], n, p=[0.99, 0.01])  # Imbalanced
        })
        
    elif "Sales" in choice:
        dates = pd.date_range('2020-01-01', '2023-12-31', freq='D')
        n = len(dates)
        trend = np.linspace(1000, 1500, n)
        seasonal = 200 * np.sin(2 * np.pi * np.arange(n) / 365.25)
        noise = np.random.normal(0, 50, n)
        
        df = pd.DataFrame({
            'date': dates,
            'sales': trend + seasonal + noise,
            'marketing_spend': np.random.exponential(100, n),
            'temperature': 20 + 15 * np.sin(2 * np.pi * np.arange(n) / 365.25) + np.random.normal(0, 5, n),
            'region': np.random.choice(['North', 'South', 'East', 'West'], n)
        })
        
    else:  # Gene Expression
        n_samples = 200
        n_genes = 1000
        
        # Create gene expression data
        gene_data = np.random.lognormal(0, 1, (n_samples, n_genes))
        gene_columns = [f'Gene_{i:04d}' for i in range(n_genes)]
        
        df = pd.DataFrame(gene_data, columns=gene_columns)
        df['sample_type'] = np.random.choice(['Control', 'Treatment'], n_samples)
        df['batch'] = np.random.choice(['Batch_A', 'Batch_B', 'Batch_C'], n_samples)
        df['patient_age'] = np.random.normal(50, 15, n_samples)
    
    return df


def show_data_preview():
    """Show data preview and basic info"""
    
    st.markdown("---")
    st.markdown("## üëÄ Data Preview")
    
    df = st.session_state.data
    
    # Basic info
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("üìä Rows", f"{len(df):,}")
    with col2:
        st.metric("üìã Columns", f"{len(df.columns)}")
    with col3:
        st.metric("üíæ Memory", f"{df.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
    with col4:
        missing_pct = (df.isnull().sum().sum() / df.size) * 100
        st.metric("‚ùì Missing", f"{missing_pct:.1f}%")
    
    # Data types
    st.markdown("### üìã Column Information")
    
    col_info = pd.DataFrame({
        'Column': df.columns,
        'Type': df.dtypes.astype(str),
        'Non-Null': df.count(),
        'Missing': df.isnull().sum(),
        'Missing %': (df.isnull().sum() / len(df) * 100).round(2)
    })
    
    st.dataframe(col_info, use_container_width=True)
    
    # Data preview
    st.markdown("### üîç Data Sample")
    
    preview_rows = st.slider("Number of rows to preview:", 5, min(100, len(df)), 10)
    st.dataframe(df.head(preview_rows), use_container_width=True)
    
    # Quick stats for numeric columns
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    if len(numeric_cols) > 0:
        st.markdown("### üìä Quick Statistics")
        st.dataframe(df[numeric_cols].describe(), use_container_width=True)


def show_eda_overview():
    """Quick EDA overview page"""
    
    if st.session_state.data is None:
        st.warning("‚ö†Ô∏è Please upload data first from the Home page.")
        return
    
    st.markdown("## üìä Quick EDA Overview")
    
    df = st.session_state.data
    
    # EDA Configuration
    with st.expander("‚öôÔ∏è EDA Configuration", expanded=True):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            target_col = st.selectbox(
                "üéØ Target Column (optional):",
                ["None"] + list(df.columns),
                help="Select target variable for supervised learning analysis"
            )
            target_col = None if target_col == "None" else target_col
        
        with col2:
            sample_size = st.number_input(
                "üìä Sample Size:",
                min_value=1000,
                max_value=100000,
                value=min(50000, len(df)),
                step=5000,
                help="Sample size for analysis (larger = more accurate but slower)"
            )
        
        with col3:
            advanced_features = st.checkbox(
                "üöÄ Advanced Features",
                value=True,
                help="Enable advanced statistical analysis and AI insights"
            )
    
    # Run EDA
    if st.button("üöÄ Run Complete EDA Analysis"):
        run_eda_analysis(df, target_col, sample_size, advanced_features)
    
    # Show results if available
    if st.session_state.eda_results is not None:
        show_eda_results()


def run_eda_analysis(df: pd.DataFrame, target_col: str, sample_size: int, advanced_features: bool):
    """Run EDA analysis with progress tracking"""
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        # Step 1: Data preparation
        status_text.text("üîÑ Preparing data...")
        progress_bar.progress(10)
        
        # Smart sampling if needed
        if len(df) > sample_size:
            sampled_df, sampling_stats = st.session_state.data_handler.create_smart_sample(
                df, target_size=sample_size, target_col=target_col
            )
            st.info(f"üìä Dataset sampled: {len(df):,} ‚Üí {len(sampled_df):,} rows ({sampling_stats['sampling_method']} sampling)")
        else:
            sampled_df = df
        
        progress_bar.progress(30)
        
        # Step 2: Run EDA
        status_text.text("üß† Running EDA analysis...")
        
        if ESSENTIAX_AVAILABLE:
            results = smart_eda(
                sampled_df,
                target=target_col,
                mode='console',
                advanced_stats=advanced_features,
                ai_insights=advanced_features,
                show_visualizations=False,
                sample_size=sample_size
            )
        else:
            # Fallback basic analysis
            results = run_basic_eda(sampled_df, target_col)
        
        progress_bar.progress(80)
        
        # Step 3: Store results
        status_text.text("üíæ Storing results...")
        st.session_state.eda_results = results
        
        # Add to history
        st.session_state.analysis_history.append({
            'timestamp': time.time(),
            'target': target_col,
            'sample_size': len(sampled_df),
            'advanced_features': advanced_features,
            'data_quality_score': results.get('data_quality_score', 'N/A')
        })
        
        progress_bar.progress(100)
        status_text.text("‚úÖ EDA analysis completed!")
        
        st.success("üéâ EDA analysis completed successfully!")
        
    except Exception as e:
        st.error(f"‚ùå EDA analysis failed: {str(e)}")
        progress_bar.empty()
        status_text.empty()


def run_basic_eda(df: pd.DataFrame, target_col: str) -> Dict[str, Any]:
    """Basic EDA analysis when EssentiaX is not available"""
    
    results = {
        'dataset_info': {
            'shape': df.shape,
            'memory_mb': df.memory_usage(deep=True).sum() / 1024**2,
            'duplicates': df.duplicated().sum()
        },
        'missing_analysis': {
            'total_missing': df.isnull().sum().sum(),
            'missing_percentage': (df.isnull().sum().sum() / df.size) * 100
        },
        'data_quality_score': 85,  # Default score
        'problem_type': 'unknown'
    }
    
    # Basic problem type inference
    if target_col and target_col in df.columns:
        if df[target_col].dtype in ['object', 'category']:
            results['problem_type'] = 'classification'
        elif df[target_col].nunique() < 20:
            results['problem_type'] = 'classification'
        else:
            results['problem_type'] = 'regression'
    
    return results


def show_eda_results():
    """Display EDA results"""
    
    results = st.session_state.eda_results
    
    st.markdown("### üìä EDA Results")
    
    # Key metrics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        quality_score = results.get('data_quality_score', 'N/A')
        st.metric("üéØ Data Quality", f"{quality_score}/100" if quality_score != 'N/A' else 'N/A')
    
    with col2:
        problem_type = results.get('problem_type', 'Unknown')
        st.metric("üîç Problem Type", problem_type.title() if problem_type else 'Unknown')
    
    with col3:
        missing_pct = results.get('missing_analysis', {}).get('missing_percentage', 0)
        st.metric("‚ùì Missing Data", f"{missing_pct:.1f}%")
    
    with col4:
        duplicates = results.get('dataset_info', {}).get('duplicates', 0)
        st.metric("üîÑ Duplicates", f"{duplicates:,}")
    
    # Detailed results in tabs
    tab1, tab2, tab3 = st.tabs(["üìã Summary", "üìä Statistics", "ü§ñ AI Insights"])
    
    with tab1:
        show_eda_summary(results)
    
    with tab2:
        show_eda_statistics(results)
    
    with tab3:
        show_eda_ai_insights(results)


def show_eda_summary(results: Dict[str, Any]):
    """Show EDA summary"""
    
    st.markdown("#### üìã Dataset Summary")
    
    dataset_info = results.get('dataset_info', {})
    
    summary_data = {
        'Metric': ['Rows', 'Columns', 'Memory Usage', 'Duplicates'],
        'Value': [
            f"{dataset_info.get('shape', (0, 0))[0]:,}",
            f"{dataset_info.get('shape', (0, 0))[1]}",
            f"{dataset_info.get('memory_mb', 0):.1f} MB",
            f"{dataset_info.get('duplicates', 0):,}"
        ]
    }
    
    st.table(pd.DataFrame(summary_data))
    
    # Missing values analysis
    missing_analysis = results.get('missing_analysis', {})
    if missing_analysis.get('missing_percentage', 0) > 0:
        st.markdown("#### ‚ùì Missing Values")
        st.warning(f"Dataset has {missing_analysis.get('missing_percentage', 0):.1f}% missing values")


def show_eda_statistics(results: Dict[str, Any]):
    """Show statistical analysis results"""
    
    st.markdown("#### üìä Statistical Analysis")
    
    # Advanced statistical analysis if available
    if 'advanced_statistical_analysis' in results:
        adv_stats = results['advanced_statistical_analysis']
        
        # Normality tests
        if 'normality_tests' in adv_stats:
            st.markdown("##### üìà Normality Tests")
            normality_data = []
            for col, result in adv_stats['normality_tests'].items():
                normality_data.append({
                    'Column': col,
                    'Normal Distribution': '‚úÖ Yes' if result.get('is_normal', False) else '‚ùå No',
                    'Consensus Score': f"{result.get('consensus_score', 0):.2f}"
                })
            
            if normality_data:
                st.dataframe(pd.DataFrame(normality_data), use_container_width=True)
        
        # Correlation analysis
        if 'advanced_correlations' in adv_stats:
            corr_result = adv_stats['advanced_correlations']
            if 'significant_pairs' in corr_result and corr_result['significant_pairs']:
                st.markdown("##### üîó Significant Correlations")
                corr_data = []
                for pair in corr_result['significant_pairs'][:10]:
                    corr_data.append({
                        'Variable 1': pair['variable1'],
                        'Variable 2': pair['variable2'],
                        'Correlation': f"{pair['pearson_r']:.3f}",
                        'Strength': pair['strength'].title(),
                        'P-value': f"{pair['pearson_p']:.4f}"
                    })
                
                st.dataframe(pd.DataFrame(corr_data), use_container_width=True)
    
    else:
        st.info("Advanced statistical analysis not available. Enable advanced features for detailed statistics.")


def show_eda_ai_insights(results: Dict[str, Any]):
    """Show AI insights and recommendations"""
    
    st.markdown("#### ü§ñ AI Insights & Recommendations")
    
    # AI recommendations if available
    if 'ai_recommendations' in results:
        recommendations = results['ai_recommendations']
        
        # Priority level
        priority = recommendations.get('priority_level', 'medium')
        priority_color = {'high': 'üî¥', 'medium': 'üü°', 'low': 'üü¢'}
        st.markdown(f"**Priority Level:** {priority_color.get(priority, 'üü°')} {priority.upper()}")
        
        # Recommendations in columns
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("##### üîß Preprocessing Steps")
            preprocessing = recommendations.get('preprocessing_steps', [])
            for i, step in enumerate(preprocessing[:5], 1):
                st.markdown(f"{i}. {step}")
        
        with col2:
            st.markdown("##### ü§ñ Model Recommendations")
            models = recommendations.get('model_selection', [])
            for i, model in enumerate(models[:5], 1):
                st.markdown(f"{i}. {model}")
        
        # Next steps
        next_steps = recommendations.get('next_steps', [])
        if next_steps:
            st.markdown("##### üöÄ Next Steps")
            for step in next_steps[:5]:
                st.markdown(f"‚Ä¢ {step}")
    
    else:
        st.info("AI insights not available. Enable advanced features for AI-powered recommendations.")


def show_advanced_stats():
    """Advanced statistical analysis page"""
    
    if st.session_state.data is None:
        st.warning("‚ö†Ô∏è Please upload data first from the Home page.")
        return
    
    st.markdown("## üî¨ Advanced Statistical Analysis")
    st.markdown("Perform comprehensive statistical tests and analysis on your data.")
    
    # Import advanced stats module
    try:
        from essentiax.eda.advanced_stats import AdvancedStatistics, test_normality, analyze_correlations, run_statistical_tests, detect_outliers
        stats_available = True
    except ImportError:
        st.error("‚ùå Advanced statistics module not available. Please ensure EssentiaX is properly installed.")
        return
    
    df = st.session_state.data
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
    all_cols = df.columns.tolist()
    
    # Create tabs for different types of analysis
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üìä Normality Tests", 
        "üîó Correlation Analysis", 
        "üìà Statistical Tests", 
        "üéØ Outlier Detection",
        "üìã Custom Analysis"
    ])
    
    # Tab 1: Normality Tests
    with tab1:
        st.markdown("### üìä Test Data Normality")
        st.markdown("Test whether your numeric variables follow a normal distribution using multiple statistical tests.")
        
        if not numeric_cols:
            st.warning("No numeric columns found in the dataset.")
        else:
            # Column selection
            col1, col2 = st.columns([2, 1])
            
            with col1:
                selected_cols = st.multiselect(
                    "Select columns to test for normality:",
                    numeric_cols,
                    default=numeric_cols[:3] if len(numeric_cols) >= 3 else numeric_cols
                )
            
            with col2:
                alpha = st.slider("Significance Level (Œ±)", 0.01, 0.10, 0.05, 0.01)
                st.markdown(f"**Current Œ± = {alpha}**")
            
            if selected_cols and st.button("üß™ Run Normality Tests", key="normality_btn"):
                with st.spinner("Running normality tests..."):
                    normality_results = []
                    
                    for col in selected_cols:
                        result = test_normality(df[col], col, alpha=alpha)
                        normality_results.append(result)
                    
                    # Display results
                    st.markdown("### üìä Normality Test Results")
                    
                    # Summary table
                    summary_data = []
                    for result in normality_results:
                        if 'tests' in result and result['tests']:
                            summary_data.append({
                                'Column': result['column'],
                                'Sample Size': result['sample_size'],
                                'Is Normal': '‚úÖ Yes' if result.get('is_normal') else '‚ùå No',
                                'Consensus Score': f"{result.get('consensus_score', 0):.2f}",
                                'Tests Performed': len(result['tests'])
                            })
                    
                    if summary_data:
                        st.dataframe(pd.DataFrame(summary_data), use_container_width=True)
                    
                    # Detailed results for each column
                    for result in normality_results:
                        if 'tests' in result and result['tests']:
                            with st.expander(f"üìà Detailed Results: {result['column']}"):
                                col1, col2 = st.columns([1, 1])
                                
                                with col1:
                                    st.markdown("**Test Results:**")
                                    for test_name, test_result in result['tests'].items():
                                        test_display_name = test_name.replace('_', ' ').title()
                                        if 'p_value' in test_result:
                                            status = "‚úÖ Normal" if test_result['is_normal'] else "‚ùå Not Normal"
                                            st.markdown(f"**{test_display_name}**: {status}")
                                            st.markdown(f"  - p-value: {test_result['p_value']:.6f}")
                                            st.markdown(f"  - statistic: {test_result['statistic']:.4f}")
                                        elif 'critical_value' in test_result:
                                            status = "‚úÖ Normal" if test_result['is_normal'] else "‚ùå Not Normal"
                                            st.markdown(f"**{test_display_name}**: {status}")
                                            st.markdown(f"  - statistic: {test_result['statistic']:.4f}")
                                            st.markdown(f"  - critical value: {test_result['critical_value']:.4f}")
                                
                                with col2:
                                    st.markdown("**Interpretation:**")
                                    st.markdown(result['interpretation'])
                                
                                # Histogram with normal overlay
                                fig = px.histogram(
                                    df, x=result['column'], 
                                    title=f"Distribution of {result['column']}",
                                    marginal="box"
                                )
                                st.plotly_chart(fig, use_container_width=True)
    
    # Tab 2: Correlation Analysis
    with tab2:
        st.markdown("### üîó Advanced Correlation Analysis")
        st.markdown("Analyze relationships between numeric variables using multiple correlation methods.")
        
        if len(numeric_cols) < 2:
            st.warning("Need at least 2 numeric columns for correlation analysis.")
        else:
            # Column selection
            col1, col2 = st.columns([2, 1])
            
            with col1:
                selected_cols = st.multiselect(
                    "Select columns for correlation analysis:",
                    numeric_cols,
                    default=numeric_cols[:5] if len(numeric_cols) >= 5 else numeric_cols,
                    key="corr_cols"
                )
            
            with col2:
                alpha = st.slider("Significance Level (Œ±)", 0.01, 0.10, 0.05, 0.01, key="corr_alpha")
                min_corr = st.slider("Minimum |correlation|", 0.0, 0.9, 0.1, 0.05)
            
            if len(selected_cols) >= 2 and st.button("üîó Analyze Correlations", key="corr_btn"):
                with st.spinner("Analyzing correlations..."):
                    corr_result = analyze_correlations(df[selected_cols], alpha=alpha)
                    
                    if 'error' not in corr_result:
                        st.markdown("### üîó Correlation Analysis Results")
                        
                        # Summary metrics
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("Variables Analyzed", len(selected_cols))
                        with col2:
                            st.metric("Sample Size", corr_result['sample_size'])
                        with col3:
                            st.metric("Significant Pairs", len(corr_result['significant_pairs']))
                        
                        # Correlation heatmaps
                        st.markdown("#### üìä Correlation Matrices")
                        
                        # Create tabs for different correlation methods
                        corr_tab1, corr_tab2, corr_tab3 = st.tabs(["Pearson", "Spearman", "Kendall"])
                        
                        with corr_tab1:
                            pearson_df = pd.DataFrame(corr_result['correlations']['pearson']['correlation_matrix'])
                            fig = px.imshow(
                                pearson_df, 
                                title="Pearson Correlation Matrix",
                                color_continuous_scale="RdBu_r",
                                aspect="auto"
                            )
                            st.plotly_chart(fig, use_container_width=True)
                        
                        with corr_tab2:
                            spearman_df = pd.DataFrame(corr_result['correlations']['spearman']['correlation_matrix'])
                            fig = px.imshow(
                                spearman_df, 
                                title="Spearman Correlation Matrix",
                                color_continuous_scale="RdBu_r",
                                aspect="auto"
                            )
                            st.plotly_chart(fig, use_container_width=True)
                        
                        with corr_tab3:
                            kendall_df = pd.DataFrame(corr_result['correlations']['kendall']['correlation_matrix'])
                            fig = px.imshow(
                                kendall_df, 
                                title="Kendall Correlation Matrix",
                                color_continuous_scale="RdBu_r",
                                aspect="auto"
                            )
                            st.plotly_chart(fig, use_container_width=True)
                        
                        # Significant correlations table
                        if corr_result['significant_pairs']:
                            st.markdown("#### üéØ Significant Correlations")
                            
                            # Filter by minimum correlation
                            filtered_pairs = [
                                pair for pair in corr_result['significant_pairs'] 
                                if abs(pair['pearson_r']) >= min_corr
                            ]
                            
                            if filtered_pairs:
                                pairs_df = pd.DataFrame(filtered_pairs)
                                pairs_df['Pearson r'] = pairs_df['pearson_r'].round(3)
                                pairs_df['P-value'] = pairs_df['pearson_p'].apply(lambda x: f"{x:.2e}" if x < 0.001 else f"{x:.3f}")
                                pairs_df['Spearman œÅ'] = pairs_df['spearman_r'].round(3)
                                pairs_df['Kendall œÑ'] = pairs_df['kendall_tau'].round(3)
                                
                                display_df = pairs_df[['variable1', 'variable2', 'Pearson r', 'P-value', 'Spearman œÅ', 'Kendall œÑ', 'strength', 'direction']]
                                display_df.columns = ['Variable 1', 'Variable 2', 'Pearson r', 'P-value', 'Spearman œÅ', 'Kendall œÑ', 'Strength', 'Direction']
                                
                                st.dataframe(display_df, use_container_width=True)
                            else:
                                st.info(f"No correlations found with |r| ‚â• {min_corr}")
                        
                        # Interpretation
                        st.markdown("#### üí° Interpretation")
                        st.markdown(corr_result['interpretation'])
                    else:
                        st.error(corr_result['error'])
    
    # Tab 3: Statistical Tests
    with tab3:
        st.markdown("### üìà Comprehensive Statistical Tests")
        st.markdown("Run various statistical tests to identify significant relationships in your data.")
        
        # Target column selection
        col1, col2 = st.columns([2, 1])
        
        with col1:
            target_col = st.selectbox(
                "Select target column (optional):",
                ["None"] + all_cols,
                key="stats_target"
            )
            if target_col == "None":
                target_col = None
        
        with col2:
            alpha = st.slider("Significance Level (Œ±)", 0.01, 0.10, 0.05, 0.01, key="stats_alpha")
        
        if st.button("üìä Run Statistical Tests", key="stats_btn"):
            with st.spinner("Running statistical tests..."):
                stats_result = run_statistical_tests(df, target_col=target_col, alpha=alpha)
                
                st.markdown("### üìä Statistical Test Results")
                
                # Summary metrics
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("Sample Size", stats_result['sample_size'])
                with col2:
                    st.metric("Numeric Columns", stats_result['numeric_columns'])
                with col3:
                    st.metric("Tests Performed", len(stats_result['tests_performed']))
                with col4:
                    st.metric("Significant Results", len(stats_result['significant_results']))
                
                # Significant results
                if stats_result['significant_results']:
                    st.markdown("#### üéØ Significant Findings")
                    
                    for i, result in enumerate(stats_result['significant_results'][:10]):  # Show top 10
                        with st.expander(f"üìà {result['test_type'].replace('_', ' ').title()} - {result.get('column', result.get('variable1', 'N/A'))}"):
                            col1, col2 = st.columns([1, 1])
                            
                            with col1:
                                st.markdown("**Test Details:**")
                                st.markdown(f"- Test Type: {result['test_type'].replace('_', ' ').title()}")
                                if 'column' in result:
                                    st.markdown(f"- Column: {result['column']}")
                                if 'target' in result:
                                    st.markdown(f"- Target: {result['target']}")
                                if 'variable1' in result and 'variable2' in result:
                                    st.markdown(f"- Variables: {result['variable1']} vs {result['variable2']}")
                                
                                # Test statistics
                                for key, value in result.items():
                                    if key.endswith('_statistic') or key.endswith('_value'):
                                        stat_name = key.replace('_', ' ').title()
                                        if isinstance(value, float):
                                            st.markdown(f"- {stat_name}: {value:.4f}")
                                        else:
                                            st.markdown(f"- {stat_name}: {value}")
                            
                            with col2:
                                st.markdown("**Interpretation:**")
                                st.markdown(result['interpretation'])
                                
                                significance = "‚úÖ Significant" if result['significant'] else "‚ùå Not Significant"
                                st.markdown(f"**Result: {significance}**")
                else:
                    st.info("No statistically significant results found.")
                
                # All tests summary
                with st.expander("üìã All Tests Summary"):
                    if stats_result['tests_performed']:
                        all_tests_df = pd.DataFrame(stats_result['tests_performed'])
                        
                        # Create summary table
                        summary_cols = ['test_type', 'significant']
                        if 'column' in all_tests_df.columns:
                            summary_cols.insert(1, 'column')
                        if 'p_value' in all_tests_df.columns:
                            summary_cols.append('p_value')
                        
                        display_df = all_tests_df[summary_cols].copy()
                        display_df['test_type'] = display_df['test_type'].str.replace('_', ' ').str.title()
                        display_df['significant'] = display_df['significant'].map({True: '‚úÖ Yes', False: '‚ùå No'})
                        
                        if 'p_value' in display_df.columns:
                            display_df['p_value'] = display_df['p_value'].apply(lambda x: f"{x:.2e}" if x < 0.001 else f"{x:.3f}")
                        
                        st.dataframe(display_df, use_container_width=True)
                
                # Overall interpretation
                st.markdown("#### üí° Overall Interpretation")
                st.markdown(stats_result['interpretation'])
    
    # Tab 4: Outlier Detection
    with tab4:
        st.markdown("### üéØ Advanced Outlier Detection")
        st.markdown("Detect outliers using multiple methods and consensus scoring.")
        
        if not numeric_cols:
            st.warning("No numeric columns found in the dataset.")
        else:
            # Column and method selection
            col1, col2 = st.columns([2, 1])
            
            with col1:
                selected_col = st.selectbox(
                    "Select column for outlier detection:",
                    numeric_cols,
                    key="outlier_col"
                )
            
            with col2:
                methods = st.multiselect(
                    "Detection methods:",
                    ['iqr', 'zscore', 'modified_zscore', 'isolation'],
                    default=['iqr', 'zscore', 'isolation'],
                    key="outlier_methods"
                )
            
            if selected_col and methods and st.button("üîç Detect Outliers", key="outlier_btn"):
                with st.spinner("Detecting outliers..."):
                    outlier_result = detect_outliers(df[selected_col], selected_col, methods=methods)
                    
                    if 'error' not in outlier_result:
                        st.markdown("### üéØ Outlier Detection Results")
                        
                        # Summary metrics
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("Sample Size", outlier_result['sample_size'])
                        with col2:
                            st.metric("Consensus Outliers", len(outlier_result['consensus_outliers']))
                        with col3:
                            st.metric("Outlier Percentage", f"{outlier_result['outlier_percentage']:.1f}%")
                        
                        # Method results
                        st.markdown("#### üìä Detection Method Results")
                        
                        method_data = []
                        for method, result in outlier_result['methods'].items():
                            method_data.append({
                                'Method': method.replace('_', ' ').title(),
                                'Outliers Found': result['outlier_count'],
                                'Percentage': f"{result['outlier_percentage']:.1f}%",
                                'Details': str(result)
                            })
                        
                        if method_data:
                            method_df = pd.DataFrame(method_data)
                            st.dataframe(method_df[['Method', 'Outliers Found', 'Percentage']], use_container_width=True)
                        
                        # Visualization
                        st.markdown("#### üìà Outlier Visualization")
                        
                        # Box plot
                        fig = px.box(df, y=selected_col, title=f"Box Plot: {selected_col}")
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # Histogram with outliers highlighted
                        fig = px.histogram(df, x=selected_col, title=f"Distribution: {selected_col}")
                        
                        # Add outlier markers if we have consensus outliers
                        if outlier_result['consensus_outliers']:
                            outlier_values = df.loc[outlier_result['consensus_outliers'], selected_col]
                            fig.add_scatter(
                                x=outlier_values,
                                y=[0] * len(outlier_values),
                                mode='markers',
                                marker=dict(color='red', size=10, symbol='x'),
                                name='Consensus Outliers'
                            )
                        
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # Interpretation
                        st.markdown("#### üí° Interpretation")
                        st.markdown(outlier_result['interpretation'])
                        
                        # Outlier values table
                        if outlier_result['consensus_outliers']:
                            with st.expander("üìã Outlier Values"):
                                outlier_df = df.loc[outlier_result['consensus_outliers'], [selected_col]].copy()
                                outlier_df['Index'] = outlier_df.index
                                outlier_df = outlier_df[['Index', selected_col]]
                                st.dataframe(outlier_df, use_container_width=True)
                    else:
                        st.error(outlier_result['error'])
    
    # Tab 5: Custom Analysis
    with tab5:
        st.markdown("### üìã Custom Statistical Analysis")
        st.markdown("Design your own statistical analysis workflow.")
        
        st.info("üöß Custom analysis builder - Coming in next update!")
        
        # Placeholder for custom analysis features
        st.markdown("**Planned Features:**")
        st.markdown("- Custom hypothesis testing")
        st.markdown("- Multi-variable analysis")
        st.markdown("- Advanced model diagnostics")
        st.markdown("- Custom statistical reports")
        
        # Quick analysis options
        st.markdown("#### ‚ö° Quick Analysis Options")
        
        if st.button("üîç Full Statistical Summary", key="full_summary"):
            with st.spinner("Generating comprehensive statistical summary..."):
                # Run all analyses
                results = {}
                
                # Normality tests for all numeric columns
                if numeric_cols:
                    st.markdown("##### üìä Normality Test Summary")
                    normality_summary = []
                    for col in numeric_cols[:5]:  # Limit to 5 columns
                        result = test_normality(df[col], col)
                        normality_summary.append({
                            'Column': col,
                            'Is Normal': '‚úÖ Yes' if result.get('is_normal') else '‚ùå No',
                            'Sample Size': result['sample_size']
                        })
                    
                    if normality_summary:
                        st.dataframe(pd.DataFrame(normality_summary), use_container_width=True)
                
                # Correlation summary
                if len(numeric_cols) >= 2:
                    st.markdown("##### üîó Correlation Summary")
                    corr_result = analyze_correlations(df[numeric_cols[:5]])  # Limit to 5 columns
                    if 'significant_pairs' in corr_result and corr_result['significant_pairs']:
                        st.markdown(f"Found {len(corr_result['significant_pairs'])} significant correlations")
                        top_corrs = corr_result['significant_pairs'][:3]
                        for i, pair in enumerate(top_corrs):
                            st.markdown(f"{i+1}. **{pair['variable1']}** ‚Üî **{pair['variable2']}**: r = {pair['pearson_r']:.3f}")
                    else:
                        st.markdown("No significant correlations found.")
                
                # Statistical tests summary
                st.markdown("##### üìà Statistical Tests Summary")
                stats_result = run_statistical_tests(df)
                st.markdown(f"- Tests performed: {len(stats_result['tests_performed'])}")
                st.markdown(f"- Significant results: {len(stats_result['significant_results'])}")
                
                st.success("‚úÖ Comprehensive statistical analysis completed!")


def show_visualizations():
    """Interactive visualizations page"""
    
    if st.session_state.data is None:
        st.warning("‚ö†Ô∏è Please upload data first from the Home page.")
        return
    
    st.markdown("## üìà Interactive Visualizations")
    st.markdown("Create custom interactive visualizations with advanced plot types and real-time customization.")
    
    # Import visualization modules
    try:
        from essentiax.visuals.smartViz import smart_viz, SmartVizEngine
        from essentiax.visuals.big_data_plots import (
            BigDataPlotter, create_diagnostic_plots, create_distribution_plots,
            create_relationship_plots, create_categorical_plots
        )
        viz_available = True
    except ImportError as e:
        st.error(f"‚ùå Visualization modules not available: {e}")
        return
    
    df = st.session_state.data
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
    all_cols = df.columns.tolist()
    
    # Create tabs for different visualization types
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "üé® Smart Viz Engine", 
        "üìä Distribution Plots", 
        "üîó Relationship Analysis", 
        "üè∑Ô∏è Categorical Analysis",
        "üî¨ Diagnostic Plots",
        "üéØ Custom Plot Builder"
    ])
    
    # Tab 1: Smart Viz Engine
    with tab1:
        st.markdown("### üé® AI-Powered Smart Visualization")
        st.markdown("Let AI automatically select the best variables and create comprehensive visualizations.")
        
        col1, col2, col3 = st.columns([2, 1, 1])
        
        with col1:
            viz_mode = st.selectbox(
                "Visualization Mode:",
                ["auto", "manual"],
                help="Auto: AI selects variables, Manual: You choose variables"
            )
        
        with col2:
            max_plots = st.slider("Max Plots", 3, 15, 8)
        
        with col3:
            sample_size = st.slider("Sample Size", 1000, 50000, 10000, step=1000)
        
        # Manual mode options
        if viz_mode == "manual":
            st.markdown("#### üéØ Manual Variable Selection")
            
            col1, col2 = st.columns(2)
            with col1:
                selected_numeric = st.multiselect(
                    "Select Numeric Variables:",
                    numeric_cols,
                    default=numeric_cols[:4] if len(numeric_cols) >= 4 else numeric_cols,
                    key="smart_viz_numeric"
                )
            
            with col2:
                selected_categorical = st.multiselect(
                    "Select Categorical Variables:",
                    categorical_cols,
                    default=categorical_cols[:2] if len(categorical_cols) >= 2 else categorical_cols,
                    key="smart_viz_categorical"
                )
            
            manual_columns = selected_numeric + selected_categorical
        else:
            manual_columns = None
        
        # Target variable selection
        target_col = st.selectbox(
            "Target Variable (optional):",
            ["None"] + all_cols,
            key="smart_viz_target"
        )
        if target_col == "None":
            target_col = None
        
        if st.button("üöÄ Generate Smart Visualizations", key="smart_viz_btn"):
            with st.spinner("üé® Creating intelligent visualizations..."):
                try:
                    # Capture the console output (since smart_viz uses Rich console)
                    st.info("üé® Smart Visualization Engine is running... Check your console for detailed insights!")
                    
                    # Run smart_viz (this will show plots in the notebook/console)
                    smart_viz(
                        df=df,
                        mode=viz_mode,
                        columns=manual_columns,
                        target=target_col,
                        max_plots=max_plots,
                        interactive=True,
                        sample_size=sample_size
                    )
                    
                    st.success("‚úÖ Smart visualizations generated! Check the plots above.")
                    st.info("üí° **Note**: The Smart Viz Engine creates interactive plots that appear above this interface. Scroll up to see the generated visualizations with AI insights.")
                    
                except Exception as e:
                    st.error(f"‚ùå Smart visualization failed: {str(e)}")
    
    # Tab 2: Distribution Plots
    with tab2:
        st.markdown("### üìä Advanced Distribution Analysis")
        st.markdown("Analyze the distribution of your variables with multiple visualization types.")
        
        if not numeric_cols:
            st.warning("No numeric columns found for distribution analysis.")
        else:
            col1, col2, col3 = st.columns([2, 1, 1])
            
            with col1:
                dist_column = st.selectbox(
                    "Select Column for Distribution Analysis:",
                    numeric_cols,
                    key="dist_column"
                )
            
            with col2:
                group_column = st.selectbox(
                    "Group by (optional):",
                    ["None"] + categorical_cols,
                    key="dist_group"
                )
                if group_column == "None":
                    group_column = None
            
            with col3:
                dist_plot_type = st.selectbox(
                    "Plot Type:",
                    ["Advanced Distribution", "Diagnostic Plots"],
                    key="dist_plot_type"
                )
            
            if st.button("üìä Create Distribution Plot", key="dist_btn"):
                with st.spinner("Creating distribution analysis..."):
                    try:
                        plotter = BigDataPlotter(max_points=10000)
                        
                        if dist_plot_type == "Diagnostic Plots":
                            fig = plotter.create_diagnostic_plots(df[dist_column], dist_column)
                            st.plotly_chart(fig, use_container_width=True)
                            
                            # Add interpretation
                            st.markdown("#### üí° Diagnostic Plot Interpretation")
                            st.markdown("""
                            - **Q-Q Plot**: Points on the diagonal line indicate normal distribution
                            - **P-P Plot**: Points on the diagonal line confirm distributional assumptions
                            - **Histogram**: Shows the actual data distribution with normal overlay
                            - **Box Plot**: Identifies outliers and quartile distribution
                            """)
                            
                        else:
                            fig = plotter.create_distribution_plots(df, dist_column, group_column)
                            st.plotly_chart(fig, use_container_width=True)
                            
                            # Add statistical summary
                            st.markdown("#### üìà Statistical Summary")
                            col1, col2, col3, col4 = st.columns(4)
                            
                            data = df[dist_column].dropna()
                            with col1:
                                st.metric("Mean", f"{data.mean():.2f}")
                            with col2:
                                st.metric("Median", f"{data.median():.2f}")
                            with col3:
                                st.metric("Std Dev", f"{data.std():.2f}")
                            with col4:
                                st.metric("Skewness", f"{data.skew():.2f}")
                        
                    except Exception as e:
                        st.error(f"‚ùå Distribution plot failed: {str(e)}")
    
    # Tab 3: Relationship Analysis
    with tab3:
        st.markdown("### üîó Relationship Analysis")
        st.markdown("Explore relationships between variables with advanced scatter plots and correlation analysis.")
        
        if len(numeric_cols) < 2:
            st.warning("Need at least 2 numeric columns for relationship analysis.")
        else:
            col1, col2, col3 = st.columns(3)
            
            with col1:
                x_column = st.selectbox(
                    "X-axis Variable:",
                    numeric_cols,
                    key="rel_x"
                )
            
            with col2:
                y_column = st.selectbox(
                    "Y-axis Variable:",
                    [col for col in numeric_cols if col != x_column],
                    key="rel_y"
                )
            
            with col3:
                color_column = st.selectbox(
                    "Color by (optional):",
                    ["None"] + categorical_cols + numeric_cols,
                    key="rel_color"
                )
                if color_column == "None":
                    color_column = None
            
            # Plot type selection
            col1, col2 = st.columns(2)
            with col1:
                rel_plot_type = st.selectbox(
                    "Plot Type:",
                    ["scatter", "regression", "hexbin"],
                    key="rel_plot_type"
                )
            
            with col2:
                show_correlation = st.checkbox("Show Correlation Matrix", value=True)
            
            if st.button("üîó Create Relationship Plot", key="rel_btn"):
                with st.spinner("Analyzing relationships..."):
                    try:
                        plotter = BigDataPlotter(max_points=10000)
                        
                        # Create relationship plot
                        fig = plotter.create_relationship_plots(
                            df, x_column, y_column, color_column, rel_plot_type
                        )
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # Show correlation matrix if requested
                        if show_correlation:
                            st.markdown("#### üî• Correlation Matrix")
                            
                            # Select relevant columns for correlation
                            corr_cols = [x_column, y_column]
                            if color_column and color_column in numeric_cols:
                                corr_cols.append(color_column)
                            
                            # Add other numeric columns
                            other_numeric = [col for col in numeric_cols if col not in corr_cols]
                            corr_cols.extend(other_numeric[:3])  # Add up to 3 more
                            
                            corr_matrix = df[corr_cols].corr()
                            
                            # Create correlation heatmap
                            fig_corr = px.imshow(
                                corr_matrix,
                                title="Correlation Matrix",
                                color_continuous_scale='RdBu_r',
                                aspect="auto"
                            )
                            st.plotly_chart(fig_corr, use_container_width=True)
                            
                            # Show correlation values
                            st.markdown("#### üìä Correlation Values")
                            correlation_value = df[x_column].corr(df[y_column])
                            
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("Pearson Correlation", f"{correlation_value:.3f}")
                            with col2:
                                spearman_corr = df[x_column].corr(df[y_column], method='spearman')
                                st.metric("Spearman Correlation", f"{spearman_corr:.3f}")
                            with col3:
                                # Correlation strength
                                if abs(correlation_value) >= 0.7:
                                    strength = "Strong"
                                elif abs(correlation_value) >= 0.4:
                                    strength = "Moderate"
                                elif abs(correlation_value) >= 0.2:
                                    strength = "Weak"
                                else:
                                    strength = "Very Weak"
                                st.metric("Relationship Strength", strength)
                        
                    except Exception as e:
                        st.error(f"‚ùå Relationship analysis failed: {str(e)}")
    
    # Tab 4: Categorical Analysis
    with tab4:
        st.markdown("### üè∑Ô∏è Categorical Data Analysis")
        st.markdown("Visualize categorical variables with various chart types.")
        
        if not categorical_cols:
            st.warning("No categorical columns found in the dataset.")
        else:
            col1, col2, col3 = st.columns(3)
            
            with col1:
                cat_column = st.selectbox(
                    "Select Categorical Column:",
                    categorical_cols,
                    key="cat_column"
                )
            
            with col2:
                value_column = st.selectbox(
                    "Value Column (optional):",
                    ["None"] + numeric_cols,
                    key="cat_value"
                )
                if value_column == "None":
                    value_column = None
            
            with col3:
                cat_plot_type = st.selectbox(
                    "Plot Type:",
                    ["bar", "pie", "sunburst"],
                    key="cat_plot_type"
                )
            
            # Additional options
            col1, col2 = st.columns(2)
            with col1:
                show_top_n = st.slider("Show Top N Categories", 5, 20, 10)
            with col2:
                show_stats = st.checkbox("Show Category Statistics", value=True)
            
            if st.button("üè∑Ô∏è Create Categorical Plot", key="cat_btn"):
                with st.spinner("Creating categorical analysis..."):
                    try:
                        plotter = BigDataPlotter(max_points=10000)
                        
                        # Limit to top N categories
                        df_limited = df.copy()
                        top_categories = df[cat_column].value_counts().head(show_top_n).index
                        df_limited = df_limited[df_limited[cat_column].isin(top_categories)]
                        
                        # Create categorical plot
                        fig = plotter.create_categorical_plots(
                            df_limited, cat_column, value_column, cat_plot_type
                        )
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # Show statistics if requested
                        if show_stats:
                            st.markdown("#### üìä Category Statistics")
                            
                            value_counts = df[cat_column].value_counts()
                            total_count = len(df)
                            
                            # Create statistics table
                            stats_data = []
                            for i, (category, count) in enumerate(value_counts.head(show_top_n).items()):
                                percentage = (count / total_count) * 100
                                stats_data.append({
                                    'Rank': i + 1,
                                    'Category': str(category),
                                    'Count': f"{count:,}",
                                    'Percentage': f"{percentage:.1f}%"
                                })
                            
                            stats_df = pd.DataFrame(stats_data)
                            st.dataframe(stats_df, use_container_width=True)
                            
                            # Summary metrics
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("Total Categories", df[cat_column].nunique())
                            with col2:
                                st.metric("Most Common", value_counts.index[0])
                            with col3:
                                st.metric("Top Category %", f"{(value_counts.iloc[0]/total_count)*100:.1f}%")
                            with col4:
                                # Calculate balance (Gini coefficient)
                                proportions = value_counts / total_count
                                gini = 1 - sum(proportions**2)
                                balance = "Balanced" if gini > 0.7 else "Imbalanced" if gini < 0.3 else "Moderate"
                                st.metric("Balance", balance)
                        
                    except Exception as e:
                        st.error(f"‚ùå Categorical analysis failed: {str(e)}")
    
    # Tab 5: Diagnostic Plots
    with tab5:
        st.markdown("### üî¨ Statistical Diagnostic Plots")
        st.markdown("Advanced diagnostic plots for statistical analysis and model validation.")
        
        if not numeric_cols:
            st.warning("No numeric columns found for diagnostic analysis.")
        else:
            col1, col2 = st.columns(2)
            
            with col1:
                diag_column = st.selectbox(
                    "Select Column for Diagnostics:",
                    numeric_cols,
                    key="diag_column"
                )
            
            with col2:
                distribution_type = st.selectbox(
                    "Compare Against Distribution:",
                    ["norm", "uniform", "exponential"],
                    key="diag_dist"
                )
            
            # Advanced options
            with st.expander("üîß Advanced Options"):
                col1, col2 = st.columns(2)
                with col1:
                    sample_for_diag = st.slider("Sample Size for Diagnostics", 1000, 10000, 5000)
                with col2:
                    show_interpretation = st.checkbox("Show Detailed Interpretation", value=True)
            
            if st.button("üî¨ Generate Diagnostic Plots", key="diag_btn"):
                with st.spinner("Creating diagnostic analysis..."):
                    try:
                        # Sample data if needed
                        data_for_diag = df[diag_column].dropna()
                        if len(data_for_diag) > sample_for_diag:
                            data_for_diag = data_for_diag.sample(n=sample_for_diag, random_state=42)
                        
                        # Create diagnostic plots
                        fig = create_diagnostic_plots(data_for_diag, diag_column, distribution_type)
                        st.plotly_chart(fig, use_container_width=True)
                        
                        if show_interpretation:
                            st.markdown("#### üí° Diagnostic Plot Interpretation Guide")
                            
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                st.markdown("""
                                **Q-Q Plot (Quantile-Quantile):**
                                - Points on diagonal = data follows expected distribution
                                - S-curve = data is skewed
                                - Curved ends = heavy/light tails
                                
                                **P-P Plot (Probability-Probability):**
                                - Points on diagonal = good distributional fit
                                - Systematic deviations = poor fit
                                - More sensitive to center of distribution
                                """)
                            
                            with col2:
                                st.markdown("""
                                **Histogram with Normal Curve:**
                                - Compare actual distribution to theoretical
                                - Look for multiple peaks (multimodal)
                                - Check for skewness and outliers
                                
                                **Box Plot:**
                                - Outliers shown as individual points
                                - Box shows quartiles (25%, 50%, 75%)
                                - Whiskers show data range
                                """)
                            
                            # Statistical tests
                            st.markdown("#### üìä Statistical Test Results")
                            
                            # Perform normality tests
                            from scipy.stats import shapiro, normaltest, anderson
                            
                            col1, col2, col3 = st.columns(3)
                            
                            # Shapiro-Wilk test
                            if len(data_for_diag) <= 5000:
                                try:
                                    shapiro_stat, shapiro_p = shapiro(data_for_diag)
                                    with col1:
                                        st.metric(
                                            "Shapiro-Wilk Test",
                                            "Normal" if shapiro_p > 0.05 else "Not Normal",
                                            f"p = {shapiro_p:.4f}"
                                        )
                                except:
                                    pass
                            
                            # D'Agostino's test
                            try:
                                dagostino_stat, dagostino_p = normaltest(data_for_diag)
                                with col2:
                                    st.metric(
                                        "D'Agostino Test",
                                        "Normal" if dagostino_p > 0.05 else "Not Normal",
                                        f"p = {dagostino_p:.4f}"
                                    )
                            except:
                                pass
                            
                            # Anderson-Darling test
                            try:
                                anderson_result = anderson(data_for_diag, dist='norm')
                                is_normal = anderson_result.statistic < anderson_result.critical_values[2]  # 5% level
                                with col3:
                                    st.metric(
                                        "Anderson-Darling",
                                        "Normal" if is_normal else "Not Normal",
                                        f"stat = {anderson_result.statistic:.4f}"
                                    )
                            except:
                                pass
                        
                    except Exception as e:
                        st.error(f"‚ùå Diagnostic analysis failed: {str(e)}")
    
    # Tab 6: Custom Plot Builder
    with tab6:
        st.markdown("### üéØ Custom Plot Builder")
        st.markdown("Build custom visualizations with full control over plot parameters.")
        
        # Plot type selection
        plot_category = st.selectbox(
            "Select Plot Category:",
            ["Distribution Plots", "Relationship Plots", "Categorical Plots", "Statistical Plots"],
            key="custom_category"
        )
        
        if plot_category == "Distribution Plots":
            st.markdown("#### üìä Distribution Plot Builder")
            
            col1, col2 = st.columns(2)
            with col1:
                custom_dist_col = st.selectbox("Column:", numeric_cols, key="custom_dist_col")
                custom_dist_type = st.selectbox(
                    "Plot Type:",
                    ["Histogram", "Box Plot", "Violin Plot", "Density Plot"],
                    key="custom_dist_type"
                )
            
            with col2:
                custom_bins = st.slider("Number of Bins (Histogram)", 10, 100, 30) if custom_dist_type == "Histogram" else None
                custom_color = st.color_picker("Plot Color", "#1f77b4")
            
            if st.button("Create Custom Distribution Plot", key="custom_dist_btn"):
                with st.spinner("Creating custom plot..."):
                    try:
                        data = df[custom_dist_col].dropna()
                        
                        if custom_dist_type == "Histogram":
                            fig = px.histogram(
                                df, x=custom_dist_col,
                                nbins=custom_bins,
                                title=f"Custom Histogram: {custom_dist_col}",
                                color_discrete_sequence=[custom_color]
                            )
                        elif custom_dist_type == "Box Plot":
                            fig = px.box(
                                df, y=custom_dist_col,
                                title=f"Custom Box Plot: {custom_dist_col}",
                                color_discrete_sequence=[custom_color]
                            )
                        elif custom_dist_type == "Violin Plot":
                            fig = px.violin(
                                df, y=custom_dist_col,
                                title=f"Custom Violin Plot: {custom_dist_col}",
                                color_discrete_sequence=[custom_color]
                            )
                        else:  # Density Plot
                            fig = px.histogram(
                                df, x=custom_dist_col,
                                marginal="rug",
                                title=f"Custom Density Plot: {custom_dist_col}",
                                color_discrete_sequence=[custom_color]
                            )
                        
                        fig.update_layout(height=500)
                        st.plotly_chart(fig, use_container_width=True)
                        
                    except Exception as e:
                        st.error(f"‚ùå Custom plot creation failed: {str(e)}")
        
        elif plot_category == "Relationship Plots":
            st.markdown("#### üîó Relationship Plot Builder")
            
            if len(numeric_cols) < 2:
                st.warning("Need at least 2 numeric columns for relationship plots.")
            else:
                col1, col2, col3 = st.columns(3)
                with col1:
                    custom_x = st.selectbox("X Variable:", numeric_cols, key="custom_x")
                with col2:
                    custom_y = st.selectbox("Y Variable:", [col for col in numeric_cols if col != custom_x], key="custom_y")
                with col3:
                    custom_size = st.selectbox("Size by:", ["None"] + numeric_cols, key="custom_size")
                    if custom_size == "None":
                        custom_size = None
                
                col1, col2 = st.columns(2)
                with col1:
                    custom_color_by = st.selectbox("Color by:", ["None"] + categorical_cols + numeric_cols, key="custom_color_by")
                    if custom_color_by == "None":
                        custom_color_by = None
                with col2:
                    add_trendline = st.checkbox("Add Trendline", value=False)
                
                if st.button("Create Custom Relationship Plot", key="custom_rel_btn"):
                    with st.spinner("Creating custom relationship plot..."):
                        try:
                            fig = px.scatter(
                                df, x=custom_x, y=custom_y,
                                color=custom_color_by,
                                size=custom_size,
                                trendline="ols" if add_trendline else None,
                                title=f"Custom Scatter Plot: {custom_x} vs {custom_y}",
                                opacity=0.7
                            )
                            
                            fig.update_layout(height=600)
                            st.plotly_chart(fig, use_container_width=True)
                            
                            # Show correlation if no color/size variables
                            if not custom_color_by and not custom_size:
                                corr = df[custom_x].corr(df[custom_y])
                                st.info(f"üìä Correlation coefficient: {corr:.3f}")
                            
                        except Exception as e:
                            st.error(f"‚ùå Custom relationship plot failed: {str(e)}")
        
        elif plot_category == "Categorical Plots":
            st.markdown("#### üè∑Ô∏è Categorical Plot Builder")
            
            if not categorical_cols:
                st.warning("No categorical columns found.")
            else:
                col1, col2 = st.columns(2)
                with col1:
                    custom_cat = st.selectbox("Categorical Variable:", categorical_cols, key="custom_cat")
                    custom_cat_type = st.selectbox(
                        "Plot Type:",
                        ["Bar Chart", "Pie Chart", "Donut Chart"],
                        key="custom_cat_type"
                    )
                
                with col2:
                    custom_cat_value = st.selectbox("Value Variable:", ["Count"] + numeric_cols, key="custom_cat_value")
                    custom_cat_limit = st.slider("Show Top N Categories", 5, 20, 10)
                
                if st.button("Create Custom Categorical Plot", key="custom_cat_btn"):
                    with st.spinner("Creating custom categorical plot..."):
                        try:
                            # Limit categories
                            if custom_cat_value == "Count":
                                value_counts = df[custom_cat].value_counts().head(custom_cat_limit)
                                plot_data = pd.DataFrame({
                                    custom_cat: value_counts.index,
                                    'Count': value_counts.values
                                })
                                y_col = 'Count'
                            else:
                                plot_data = df.groupby(custom_cat)[custom_cat_value].mean().reset_index()
                                plot_data = plot_data.nlargest(custom_cat_limit, custom_cat_value)
                                y_col = custom_cat_value
                            
                            if custom_cat_type == "Bar Chart":
                                fig = px.bar(
                                    plot_data, x=custom_cat, y=y_col,
                                    title=f"Custom Bar Chart: {custom_cat}"
                                )
                            elif custom_cat_type == "Pie Chart":
                                fig = px.pie(
                                    plot_data, names=custom_cat, values=y_col,
                                    title=f"Custom Pie Chart: {custom_cat}"
                                )
                            else:  # Donut Chart
                                fig = px.pie(
                                    plot_data, names=custom_cat, values=y_col,
                                    title=f"Custom Donut Chart: {custom_cat}",
                                    hole=0.4
                                )
                            
                            fig.update_layout(height=500)
                            st.plotly_chart(fig, use_container_width=True)
                            
                        except Exception as e:
                            st.error(f"‚ùå Custom categorical plot failed: {str(e)}")
        
        else:  # Statistical Plots
            st.markdown("#### üìä Statistical Plot Builder")
            
            col1, col2 = st.columns(2)
            with col1:
                stat_plot_type = st.selectbox(
                    "Statistical Plot Type:",
                    ["Correlation Heatmap", "Pair Plot", "Distribution Comparison"],
                    key="stat_plot_type"
                )
            
            with col2:
                if stat_plot_type in ["Correlation Heatmap", "Pair Plot"]:
                    stat_columns = st.multiselect(
                        "Select Variables:",
                        numeric_cols,
                        default=numeric_cols[:5] if len(numeric_cols) >= 5 else numeric_cols,
                        key="stat_columns"
                    )
                else:
                    stat_columns = st.multiselect(
                        "Select Variables to Compare:",
                        numeric_cols,
                        default=numeric_cols[:3] if len(numeric_cols) >= 3 else numeric_cols,
                        key="stat_compare_columns"
                    )
            
            if st.button("Create Statistical Plot", key="stat_btn"):
                with st.spinner("Creating statistical plot..."):
                    try:
                        if stat_plot_type == "Correlation Heatmap" and len(stat_columns) >= 2:
                            corr_matrix = df[stat_columns].corr()
                            fig = px.imshow(
                                corr_matrix,
                                title="Custom Correlation Heatmap",
                                color_continuous_scale='RdBu_r',
                                aspect="auto"
                            )
                            st.plotly_chart(fig, use_container_width=True)
                            
                        elif stat_plot_type == "Pair Plot" and len(stat_columns) >= 2:
                            # Limit to 6 variables for readability
                            plot_cols = stat_columns[:6]
                            fig = px.scatter_matrix(
                                df[plot_cols],
                                title="Custom Pair Plot"
                            )
                            fig.update_layout(height=800)
                            st.plotly_chart(fig, use_container_width=True)
                            
                        elif stat_plot_type == "Distribution Comparison" and len(stat_columns) >= 2:
                            # Create overlaid histograms
                            fig = go.Figure()
                            colors = px.colors.qualitative.Set1
                            
                            for i, col in enumerate(stat_columns[:5]):  # Limit to 5 for clarity
                                fig.add_trace(go.Histogram(
                                    x=df[col].dropna(),
                                    name=col,
                                    opacity=0.7,
                                    marker_color=colors[i % len(colors)]
                                ))
                            
                            fig.update_layout(
                                title="Distribution Comparison",
                                barmode='overlay',
                                height=500
                            )
                            st.plotly_chart(fig, use_container_width=True)
                        
                        else:
                            st.warning("Please select appropriate variables for the chosen plot type.")
                            
                    except Exception as e:
                        st.error(f"‚ùå Statistical plot creation failed: {str(e)}")
    
    # Add a footer with tips
    st.markdown("---")
    st.markdown("### üí° Visualization Tips")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        **üé® Smart Viz Engine:**
        - Use 'auto' mode for AI-powered analysis
        - Perfect for exploratory data analysis
        - Provides detailed insights with plots
        """)
    
    with col2:
        st.markdown("""
        **üìä Distribution Analysis:**
        - Check normality before statistical tests
        - Use diagnostic plots for model validation
        - Group by categorical variables for comparisons
        """)
    
    with col3:
        st.markdown("""
        **üîó Relationship Analysis:**
        - Start with correlation matrix
        - Use color coding to reveal patterns
        - Add trendlines to identify relationships
        """)


def show_ai_insights():
    """AI insights and recommendations page"""
    
    if st.session_state.data is None:
        st.warning("‚ö†Ô∏è Please upload data first from the Home page.")
        return
    
    st.markdown("## ü§ñ AI Insights & Recommendations")
    st.markdown("Get AI-powered insights, data quality assessments, and actionable recommendations for your data science workflow.")
    
    # Import AI modules
    try:
        from essentiax.ai.advanced_insights import (
            AdvancedInsightsEngine, assess_data_quality, generate_recommendations
        )
        # Use AdvancedInsightsEngine as AIInsightsEngine since it provides similar functionality
        AIInsightsEngine = AdvancedInsightsEngine
        ai_available = True
    except ImportError as e:
        st.error(f"‚ùå AI modules not available: {e}")
        return
    
    df = st.session_state.data
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
    all_cols = df.columns.tolist()
    
    # Create tabs for different AI analysis types
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üéØ Data Quality Assessment", 
        "üß† AI Insights Engine", 
        "üìã Actionable Recommendations", 
        "üîÆ Predictive Insights",
        "üíº Business Intelligence"
    ])
    
    # Tab 1: Data Quality Assessment
    with tab1:
        st.markdown("### üéØ Comprehensive Data Quality Assessment")
        st.markdown("AI-powered analysis of your data quality across multiple dimensions.")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            target_col = st.selectbox(
                "Target Column (optional):",
                ["None"] + all_cols,
                key="quality_target"
            )
            if target_col == "None":
                target_col = None
        
        with col2:
            include_detailed = st.checkbox("Include Detailed Analysis", value=True)
        
        if st.button("üîç Assess Data Quality", key="quality_btn"):
            with st.spinner("ü§ñ AI is analyzing your data quality..."):
                try:
                    # Run data quality assessment
                    quality_results = assess_data_quality(df, target_col)
                    
                    # Display overall quality score
                    st.markdown("### üìä Overall Data Quality Score")
                    
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        score = quality_results['overall_score']
                        color = "green" if score >= 80 else "orange" if score >= 60 else "red"
                        st.metric("Overall Score", f"{score:.1f}/100", delta=None)
                    
                    with col2:
                        readiness = quality_results['model_readiness']
                        readiness_display = {
                            'ready': '‚úÖ Ready',
                            'needs_minor_cleanup': '‚ö†Ô∏è Minor Cleanup',
                            'needs_major_cleanup': 'üîß Major Cleanup',
                            'not_ready': '‚ùå Not Ready'
                        }
                        st.metric("Model Readiness", readiness_display.get(readiness, readiness))
                    
                    with col3:
                        st.metric("Quality Issues", len(quality_results['quality_issues']))
                    
                    with col4:
                        st.metric("Recommendations", len(quality_results['improvement_recommendations']))
                    
                    # Display dimension scores
                    if include_detailed:
                        st.markdown("### üìà Quality Dimensions Breakdown")
                        
                        dimension_data = []
                        for dimension, score in quality_results['dimension_scores'].items():
                            dimension_data.append({
                                'Dimension': dimension.replace('_', ' ').title(),
                                'Score': f"{score:.1f}",
                                'Status': '‚úÖ Good' if score >= 80 else '‚ö†Ô∏è Fair' if score >= 60 else '‚ùå Poor'
                            })
                        
                        dimension_df = pd.DataFrame(dimension_data)
                        st.dataframe(dimension_df, use_container_width=True)
                        
                        # Create quality radar chart
                        import plotly.graph_objects as go
                        
                        dimensions = list(quality_results['dimension_scores'].keys())
                        scores = list(quality_results['dimension_scores'].values())
                        
                        fig = go.Figure()
                        fig.add_trace(go.Scatterpolar(
                            r=scores,
                            theta=[dim.replace('_', ' ').title() for dim in dimensions],
                            fill='toself',
                            name='Data Quality',
                            line_color='rgb(0, 123, 255)'
                        ))
                        
                        fig.update_layout(
                            polar=dict(
                                radialaxis=dict(
                                    visible=True,
                                    range=[0, 100]
                                )),
                            showlegend=False,
                            title="Data Quality Radar Chart"
                        )
                        
                        st.plotly_chart(fig, use_container_width=True)
                    
                    # Display quality issues
                    if quality_results['quality_issues']:
                        st.markdown("### ‚ö†Ô∏è Identified Quality Issues")
                        
                        for i, issue in enumerate(quality_results['quality_issues'], 1):
                            with st.expander(f"Issue {i}: {issue}"):
                                st.markdown(f"**Description:** {issue}")
                                st.markdown("**Impact:** This issue may affect model performance and reliability.")
                    
                    # Display improvement recommendations
                    if quality_results['improvement_recommendations']:
                        st.markdown("### üí° Quality Improvement Recommendations")
                        
                        for i, rec in enumerate(quality_results['improvement_recommendations'], 1):
                            st.markdown(f"{i}. {rec}")
                    
                    # Store results in session state for other tabs
                    st.session_state.quality_results = quality_results
                    
                except Exception as e:
                    st.error(f"‚ùå Data quality assessment failed: {str(e)}")
    
    # Tab 2: AI Insights Engine
    with tab2:
        st.markdown("### üß† Advanced AI Insights Engine")
        st.markdown("Deep AI analysis with statistical interpretations and pattern detection.")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            target_col = st.selectbox(
                "Target Column (optional):",
                ["None"] + all_cols,
                key="insights_target"
            )
            if target_col == "None":
                target_col = None
        
        with col2:
            analysis_depth = st.selectbox(
                "Analysis Depth:",
                ["Quick", "Standard", "Comprehensive"],
                index=1,
                key="analysis_depth"
            )
        
        with col3:
            confidence_threshold = st.slider(
                "Confidence Threshold:",
                0.5, 1.0, 0.8, 0.05,
                key="confidence_threshold"
            )
        
        if st.button("üöÄ Generate AI Insights", key="insights_btn"):
            with st.spinner("ü§ñ AI is analyzing patterns and generating insights..."):
                try:
                    # Initialize AI engine
                    ai_engine = AIInsightsEngine()
                    
                    # Generate comprehensive insights using data quality assessment
                    quality_results = ai_engine.assess_data_quality(df, target_col)
                    
                    # Mock the insights structure expected by the UI
                    insights = {
                        'data_quality_insights': quality_results,
                        'statistical_insights': {'distribution_insights': [], 'correlation_insights': []},
                        'pattern_insights': {'patterns': []},
                        'feature_insights': {'important_features': []},
                        'anomaly_insights': {'anomalies_detected': 0, 'anomaly_percentage': 0.0}
                    }
                    
                    # Display insights in organized sections
                    st.markdown("### üéØ Key AI Insights")
                    
                    # Data Quality Insights
                    if 'data_quality_insights' in insights:
                        quality_insights = insights['data_quality_insights']
                        
                        with st.expander("üìä Data Quality Analysis", expanded=True):
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                st.metric("Quality Score", f"{quality_insights['overall_score']:.1f}/100")
                                st.metric("Issues Found", len(quality_insights['issues']))
                            
                            with col2:
                                if quality_insights['issues']:
                                    st.markdown("**Top Issues:**")
                                    for issue in quality_insights['issues'][:3]:
                                        severity_emoji = {"high": "üî¥", "medium": "üü°", "low": "üü¢"}
                                        st.markdown(f"{severity_emoji.get(issue['severity'], '‚ö™')} {issue['description']}")
                    
                    # Statistical Insights
                    if 'statistical_insights' in insights:
                        stat_insights = insights['statistical_insights']
                        
                        with st.expander("üìà Statistical Analysis"):
                            if stat_insights.get('distribution_insights'):
                                st.markdown("**Distribution Analysis:**")
                                for dist in stat_insights['distribution_insights'][:5]:
                                    col_name = dist['column']
                                    interpretation = dist['interpretation']
                                    st.markdown(f"‚Ä¢ **{col_name}**: {interpretation}")
                            
                            if stat_insights.get('correlation_insights'):
                                st.markdown("**Correlation Insights:**")
                                for corr in stat_insights['correlation_insights'][:5]:
                                    st.markdown(f"‚Ä¢ **{corr['var1']} ‚Üî {corr['var2']}**: {corr['strength']} correlation (r={corr['correlation']:.3f})")
                    
                    # Pattern Insights
                    if 'pattern_insights' in insights:
                        with st.expander("üîç Pattern Detection"):
                            pattern_insights = insights['pattern_insights']
                            if pattern_insights:
                                st.markdown("**Detected Patterns:**")
                                for pattern in pattern_insights.get('patterns', [])[:5]:
                                    st.markdown(f"‚Ä¢ {pattern}")
                            else:
                                st.info("No significant patterns detected in the data.")
                    
                    # Feature Insights
                    if 'feature_insights' in insights and target_col:
                        with st.expander("üéØ Feature Analysis"):
                            feature_insights = insights['feature_insights']
                            if feature_insights.get('important_features'):
                                st.markdown("**Most Important Features:**")
                                for i, feature in enumerate(feature_insights['important_features'][:5], 1):
                                    st.markdown(f"{i}. **{feature['feature']}** (importance: {feature['importance']:.3f})")
                    
                    # Anomaly Insights
                    if 'anomaly_insights' in insights:
                        with st.expander("üö® Anomaly Detection"):
                            anomaly_insights = insights['anomaly_insights']
                            if anomaly_insights.get('anomalies_detected', 0) > 0:
                                st.warning(f"‚ö†Ô∏è {anomaly_insights['anomalies_detected']} anomalies detected")
                                st.markdown("**Anomaly Summary:**")
                                st.markdown(f"‚Ä¢ Anomaly percentage: {anomaly_insights.get('anomaly_percentage', 0):.1f}%")
                                st.markdown("‚Ä¢ Consider investigating these data points for errors or outliers")
                            else:
                                st.success("‚úÖ No significant anomalies detected")
                    
                    # Store insights for other tabs
                    st.session_state.ai_insights = insights
                    
                except Exception as e:
                    st.error(f"‚ùå AI insights generation failed: {str(e)}")
    
    # Tab 3: Actionable Recommendations
    with tab3:
        st.markdown("### üìã Actionable Data Science Recommendations")
        st.markdown("Get specific, prioritized recommendations for your data science workflow.")
        
        col1, col2 = st.columns(2)
        
        with col1:
            target_col = st.selectbox(
                "Target Column (optional):",
                ["None"] + all_cols,
                key="rec_target"
            )
            if target_col == "None":
                target_col = None
        
        with col2:
            problem_type = st.selectbox(
                "Problem Type:",
                ["Auto-detect", "Classification", "Regression", "Clustering", "Anomaly Detection"],
                key="problem_type"
            )
        
        # Advanced options
        with st.expander("üîß Advanced Options"):
            col1, col2 = st.columns(2)
            with col1:
                include_preprocessing = st.checkbox("Include Preprocessing Steps", value=True)
                include_feature_eng = st.checkbox("Include Feature Engineering", value=True)
            with col2:
                include_model_rec = st.checkbox("Include Model Recommendations", value=True)
                include_validation = st.checkbox("Include Validation Strategy", value=True)
        
        if st.button("üìã Generate Recommendations", key="rec_btn"):
            with st.spinner("ü§ñ Generating actionable recommendations..."):
                try:
                    # Prepare analysis results (mock structure for now)
                    analysis_results = {
                        'problem_type': problem_type.lower() if problem_type != "Auto-detect" else None,
                        'data_quality_score': getattr(st.session_state, 'quality_results', {}).get('overall_score', 85),
                        'missing_analysis': {
                            'missing_percentage': (df.isnull().sum().sum() / df.size) * 100,
                            'total_missing': df.isnull().sum().sum()
                        },
                        'target_analysis': {
                            'imbalance_detected': False
                        }
                    }
                    
                    # Generate recommendations
                    recommendations = generate_recommendations(df, analysis_results, target_col)
                    
                    # Display priority level
                    priority_colors = {'high': 'üî¥', 'medium': 'üü°', 'low': 'üü¢'}
                    priority_emoji = priority_colors.get(recommendations['priority_level'], '‚ö™')
                    
                    st.markdown(f"### {priority_emoji} Priority Level: {recommendations['priority_level'].title()}")
                    
                    # Preprocessing Recommendations
                    if include_preprocessing and recommendations['preprocessing_steps']:
                        st.markdown("### üîß Preprocessing Recommendations")
                        for i, step in enumerate(recommendations['preprocessing_steps'], 1):
                            st.markdown(f"{i}. {step}")
                    
                    # Feature Engineering Recommendations
                    if include_feature_eng and recommendations['feature_engineering']:
                        st.markdown("### ‚öôÔ∏è Feature Engineering Recommendations")
                        for i, step in enumerate(recommendations['feature_engineering'], 1):
                            st.markdown(f"{i}. {step}")
                    
                    # Model Selection Recommendations
                    if include_model_rec and recommendations['model_selection']:
                        st.markdown("### ü§ñ Model Selection Recommendations")
                        for i, model in enumerate(recommendations['model_selection'], 1):
                            st.markdown(f"{i}. {model}")
                    
                    # Validation Strategy
                    if include_validation and recommendations['validation_strategy']:
                        st.markdown("### ‚úÖ Validation Strategy Recommendations")
                        for i, strategy in enumerate(recommendations['validation_strategy'], 1):
                            st.markdown(f"{i}. {strategy}")
                    
                    # Business Insights
                    if recommendations['business_insights']:
                        st.markdown("### üíº Business Insights")
                        for i, insight in enumerate(recommendations['business_insights'], 1):
                            st.markdown(f"{i}. {insight}")
                    
                    # Next Steps Roadmap
                    if recommendations['next_steps']:
                        st.markdown("### üó∫Ô∏è Next Steps Roadmap")
                        for step in recommendations['next_steps']:
                            st.markdown(f"‚Ä¢ {step}")
                    
                    # Store recommendations
                    st.session_state.recommendations = recommendations
                    
                except Exception as e:
                    st.error(f"‚ùå Recommendation generation failed: {str(e)}")
    
    # Tab 4: Predictive Insights
    with tab4:
        st.markdown("### üîÆ Predictive Insights & Model Readiness")
        st.markdown("AI-powered predictions about model performance and data science outcomes.")
        
        if not target_col or target_col == "None":
            st.info("üí° Select a target column in the previous tabs to enable predictive insights.")
        else:
            col1, col2 = st.columns(2)
            
            with col1:
                model_type = st.selectbox(
                    "Model Type:",
                    ["Auto-detect", "Classification", "Regression"],
                    key="pred_model_type"
                )
            
            with col2:
                performance_metric = st.selectbox(
                    "Primary Metric:",
                    ["Auto-select", "Accuracy", "F1-Score", "ROC-AUC", "RMSE", "R¬≤"],
                    key="performance_metric"
                )
            
            if st.button("üîÆ Generate Predictive Insights", key="pred_btn"):
                with st.spinner("ü§ñ Analyzing predictive potential..."):
                    try:
                        # Mock predictive analysis (in real implementation, this would use ML models)
                        st.markdown("### üéØ Model Performance Predictions")
                        
                        col1, col2, col3, col4 = st.columns(4)
                        
                        with col1:
                            # Estimate based on data quality and size
                            data_quality = getattr(st.session_state, 'quality_results', {}).get('overall_score', 85)
                            predicted_accuracy = min(95, max(60, data_quality * 0.8 + np.random.normal(5, 2)))
                            st.metric("Predicted Accuracy", f"{predicted_accuracy:.1f}%")
                        
                        with col2:
                            # Estimate training time based on data size
                            n_samples = len(df)
                            if n_samples < 1000:
                                training_time = "< 1 min"
                            elif n_samples < 10000:
                                training_time = "1-5 min"
                            else:
                                training_time = "5-30 min"
                            st.metric("Est. Training Time", training_time)
                        
                        with col3:
                            # Feature importance prediction
                            n_features = len(df.columns) - 1
                            important_features = min(10, max(3, n_features // 3))
                            st.metric("Key Features", f"~{important_features}")
                        
                        with col4:
                            # Model complexity recommendation
                            if n_samples > 10000 and n_features > 20:
                                complexity = "High"
                            elif n_samples > 1000:
                                complexity = "Medium"
                            else:
                                complexity = "Low"
                            st.metric("Recommended Complexity", complexity)
                        
                        # Detailed predictions
                        st.markdown("### üìä Detailed Predictions")
                        
                        predictions = [
                            f"üéØ **Model Performance**: Based on data quality ({data_quality:.1f}/100), expect {predicted_accuracy:.1f}% accuracy",
                            f"üìà **Feature Importance**: Approximately {important_features} features will drive 80% of model performance",
                            f"‚è±Ô∏è **Training Time**: Estimated {training_time} for initial model training",
                            f"üîß **Optimization Potential**: {10 + (100-data_quality)//5}% improvement possible with data cleaning",
                            f"üìä **Cross-Validation**: Expect ¬±{max(2, (100-data_quality)//10)}% variance in performance metrics"
                        ]
                        
                        for prediction in predictions:
                            st.markdown(prediction)
                        
                        # Risk assessment
                        st.markdown("### ‚ö†Ô∏è Risk Assessment")
                        
                        risks = []
                        if data_quality < 70:
                            risks.append("üî¥ **High Risk**: Low data quality may lead to unreliable models")
                        if n_samples < 1000:
                            risks.append("üü° **Medium Risk**: Small dataset may cause overfitting")
                        if len(numeric_cols) < 3:
                            risks.append("üü° **Medium Risk**: Limited numeric features may restrict model options")
                        
                        if not risks:
                            st.success("‚úÖ **Low Risk**: Data characteristics support reliable model development")
                        else:
                            for risk in risks:
                                st.markdown(risk)
                        
                    except Exception as e:
                        st.error(f"‚ùå Predictive insights generation failed: {str(e)}")
    
    # Tab 5: Business Intelligence
    with tab5:
        st.markdown("### üíº Business Intelligence & Impact Analysis")
        st.markdown("Translate technical insights into business value and strategic recommendations.")
        
        col1, col2 = st.columns(2)
        
        with col1:
            business_context = st.selectbox(
                "Business Context:",
                ["General", "Marketing", "Finance", "Operations", "Product", "Customer Analytics"],
                key="business_context"
            )
        
        with col2:
            impact_focus = st.selectbox(
                "Impact Focus:",
                ["ROI", "Cost Reduction", "Revenue Growth", "Risk Mitigation", "Efficiency"],
                key="impact_focus"
            )
        
        if st.button("üíº Generate Business Intelligence", key="bi_btn"):
            with st.spinner("ü§ñ Analyzing business impact..."):
                try:
                    st.markdown("### üí∞ Business Impact Analysis")
                    
                    # Mock business intelligence (in real implementation, this would be more sophisticated)
                    data_size = len(df)
                    n_features = len(df.columns)
                    data_quality = getattr(st.session_state, 'quality_results', {}).get('overall_score', 85)
                    
                    # Business value metrics
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        # Estimate potential ROI based on data quality and size
                        roi_estimate = min(500, max(50, data_quality * 3 + data_size // 100))
                        st.metric("Estimated ROI", f"{roi_estimate}%")
                    
                    with col2:
                        # Time to value
                        if data_quality > 80:
                            ttv = "2-4 weeks"
                        elif data_quality > 60:
                            ttv = "4-8 weeks"
                        else:
                            ttv = "8-12 weeks"
                        st.metric("Time to Value", ttv)
                    
                    with col3:
                        # Implementation complexity
                        if data_quality > 80 and data_size < 10000:
                            complexity = "Low"
                        elif data_quality > 60:
                            complexity = "Medium"
                        else:
                            complexity = "High"
                        st.metric("Implementation", complexity)
                    
                    with col4:
                        # Business risk
                        if data_quality > 80:
                            risk = "Low"
                        elif data_quality > 60:
                            risk = "Medium"
                        else:
                            risk = "High"
                        st.metric("Business Risk", risk)
                    
                    # Context-specific insights
                    st.markdown(f"### üéØ {business_context} Insights")
                    
                    context_insights = {
                        "Marketing": [
                            "üìä Customer segmentation opportunities identified",
                            "üéØ Personalization potential based on feature diversity",
                            "üìà Campaign optimization through predictive modeling",
                            "üí∞ Customer lifetime value prediction feasibility"
                        ],
                        "Finance": [
                            "üí≥ Risk assessment model development potential",
                            "üìä Fraud detection capabilities based on anomaly patterns",
                            "üí∞ Revenue forecasting accuracy expectations",
                            "‚öñÔ∏è Regulatory compliance considerations"
                        ],
                        "Operations": [
                            "‚öôÔ∏è Process optimization opportunities",
                            "üìà Efficiency improvement potential",
                            "üîß Predictive maintenance feasibility",
                            "üìä Resource allocation optimization"
                        ],
                        "Product": [
                            "üöÄ Feature usage analysis potential",
                            "üë• User behavior prediction capabilities",
                            "üìä Product recommendation system feasibility",
                            "üí° Innovation opportunities from data patterns"
                        ],
                        "Customer Analytics": [
                            "üë• Customer behavior prediction accuracy",
                            "üîÑ Churn prediction model potential",
                            "üí∞ Revenue impact from customer insights",
                            "üìä Satisfaction scoring opportunities"
                        ]
                    }
                    
                    insights = context_insights.get(business_context, [
                        "üìä Data-driven decision making enhancement",
                        "üéØ Predictive analytics implementation potential",
                        "üí∞ Cost reduction through automation",
                        "üìà Performance improvement opportunities"
                    ])
                    
                    for insight in insights:
                        st.markdown(f"‚Ä¢ {insight}")
                    
                    # Strategic recommendations
                    st.markdown("### üó∫Ô∏è Strategic Recommendations")
                    
                    strategic_recs = [
                        f"üéØ **Immediate Action**: Focus on {impact_focus.lower()} through data quality improvement",
                        f"üìä **Short-term Goal**: Implement baseline models within {ttv}",
                        f"üöÄ **Long-term Vision**: Scale to enterprise-wide {business_context.lower()} analytics",
                        f"üí∞ **Investment Priority**: Allocate resources based on {roi_estimate}% ROI potential"
                    ]
                    
                    for rec in strategic_recs:
                        st.markdown(rec)
                    
                    # Success metrics
                    st.markdown("### üìè Success Metrics to Track")
                    
                    success_metrics = [
                        "üìä Model accuracy improvement over baseline",
                        "‚è±Ô∏è Time reduction in decision-making processes",
                        "üí∞ Cost savings from automated insights",
                        "üìà Revenue increase from data-driven actions",
                        "üéØ User adoption rate of AI recommendations"
                    ]
                    
                    for metric in success_metrics:
                        st.markdown(f"‚Ä¢ {metric}")
                    
                except Exception as e:
                    st.error(f"‚ùå Business intelligence generation failed: {str(e)}")
    
    # Add footer with tips
    st.markdown("---")
    st.markdown("### üí° AI Insights Tips")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        **üéØ Data Quality:**
        - Higher quality = better predictions
        - Focus on completeness and consistency
        - Address issues before modeling
        """)
    
    with col2:
        st.markdown("""
        **üß† AI Insights:**
        - Review statistical interpretations
        - Validate patterns with domain knowledge
        - Use confidence thresholds appropriately
        """)
    
    with col3:
        st.markdown("""
        **üìã Recommendations:**
        - Prioritize by business impact
        - Start with high-confidence suggestions
        - Iterate based on results
        """)


def show_export_reports():
    """Export and reports page"""
    
    if st.session_state.data is None:
        st.warning("‚ö†Ô∏è Please upload data first from the Home page.")
        return
    
    st.markdown("## üìã Export & Reports")
    st.markdown("Generate comprehensive reports and export your analysis results in various formats.")
    
    df = st.session_state.data
    
    # Create tabs for different export options
    tab1, tab2, tab3, tab4 = st.tabs([
        "üìä Analysis Summary", 
        "üìÑ Generate Reports", 
        "üíæ Export Data", 
        "üìà Custom Reports"
    ])
    
    # Tab 1: Analysis Summary
    with tab1:
        st.markdown("### üìä Analysis Summary")
        st.markdown("Overview of all analyses performed on your dataset.")
        
        # Dataset Overview
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("üìä Total Rows", f"{len(df):,}")
        with col2:
            st.metric("üìã Total Columns", f"{len(df.columns)}")
        with col3:
            missing_pct = (df.isnull().sum().sum() / df.size) * 100
            st.metric("‚ùì Missing Data", f"{missing_pct:.1f}%")
        with col4:
            memory_mb = df.memory_usage(deep=True).sum() / 1024**2
            st.metric("üíæ Memory Usage", f"{memory_mb:.1f} MB")
        
        # Analysis History
        if hasattr(st.session_state, 'analysis_history') and st.session_state.analysis_history:
            st.markdown("### üìà Analysis History")
            
            history_data = []
            for i, analysis in enumerate(st.session_state.analysis_history, 1):
                timestamp = pd.to_datetime(analysis['timestamp'], unit='s')
                history_data.append({
                    'Analysis #': i,
                    'Timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S'),
                    'Target Column': analysis.get('target', 'None'),
                    'Sample Size': f"{analysis.get('sample_size', 0):,}",
                    'Advanced Features': '‚úÖ' if analysis.get('advanced_features', False) else '‚ùå',
                    'Quality Score': analysis.get('data_quality_score', 'N/A')
                })
            
            if history_data:
                st.dataframe(pd.DataFrame(history_data), use_container_width=True)
        else:
            st.info("No analysis history available. Run some analyses first!")
        
        # Quick Statistics
        st.markdown("### üìä Quick Statistics")
        
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        categorical_cols = df.select_dtypes(include=['object', 'category']).columns
        
        col1, col2 = st.columns(2)
        
        with col1:
            if len(numeric_cols) > 0:
                st.markdown("**Numeric Columns:**")
                numeric_stats = df[numeric_cols].describe()
                st.dataframe(numeric_stats, use_container_width=True)
        
        with col2:
            if len(categorical_cols) > 0:
                st.markdown("**Categorical Columns:**")
                cat_stats = []
                for col in categorical_cols:
                    cat_stats.append({
                        'Column': col,
                        'Unique Values': df[col].nunique(),
                        'Most Frequent': df[col].mode().iloc[0] if len(df[col].mode()) > 0 else 'N/A',
                        'Missing': df[col].isnull().sum()
                    })
                
                if cat_stats:
                    st.dataframe(pd.DataFrame(cat_stats), use_container_width=True)
    
    # Tab 2: Generate Reports
    with tab2:
        st.markdown("### üìÑ Generate Comprehensive Reports")
        st.markdown("Create detailed reports in various formats.")
        
        # Report Configuration
        with st.expander("‚öôÔ∏è Report Configuration", expanded=True):
            col1, col2, col3 = st.columns(3)
            
            with col1:
                report_title = st.text_input("Report Title:", value=f"EDA Report - {pd.Timestamp.now().strftime('%Y-%m-%d')}")
                include_summary = st.checkbox("Include Dataset Summary", value=True)
                include_statistics = st.checkbox("Include Statistical Analysis", value=True)
            
            with col2:
                include_visualizations = st.checkbox("Include Visualizations", value=True)
                include_quality_assessment = st.checkbox("Include Data Quality Assessment", value=True)
                include_recommendations = st.checkbox("Include AI Recommendations", value=True)
            
            with col3:
                report_format = st.selectbox("Report Format:", ["HTML", "PDF", "Markdown"])
                include_code = st.checkbox("Include Code Examples", value=False)
                include_appendix = st.checkbox("Include Technical Appendix", value=True)
        
        # Generate Report Button
        if st.button("üìÑ Generate Report", key="generate_report"):
            with st.spinner("üîÑ Generating comprehensive report..."):
                try:
                    # Generate report content
                    report_content = generate_report_content(
                        df, 
                        report_title,
                        include_summary,
                        include_statistics,
                        include_visualizations,
                        include_quality_assessment,
                        include_recommendations,
                        include_code,
                        include_appendix
                    )
                    
                    if report_format == "HTML":
                        # Display HTML report
                        st.markdown("### üìÑ Generated Report")
                        st.markdown(report_content, unsafe_allow_html=True)
                        
                        # Download button
                        st.download_button(
                            label="üíæ Download HTML Report",
                            data=report_content,
                            file_name=f"{report_title.replace(' ', '_')}.html",
                            mime="text/html"
                        )
                    
                    elif report_format == "Markdown":
                        # Display Markdown report
                        st.markdown("### üìÑ Generated Report")
                        st.markdown(report_content)
                        
                        # Download button
                        st.download_button(
                            label="üíæ Download Markdown Report",
                            data=report_content,
                            file_name=f"{report_title.replace(' ', '_')}.md",
                            mime="text/markdown"
                        )
                    
                    else:  # PDF
                        st.info("üìÑ PDF generation requires additional setup. Showing HTML preview instead.")
                        st.markdown(report_content, unsafe_allow_html=True)
                        
                        # Download HTML as fallback
                        st.download_button(
                            label="üíæ Download HTML Report (PDF alternative)",
                            data=report_content,
                            file_name=f"{report_title.replace(' ', '_')}.html",
                            mime="text/html"
                        )
                    
                    st.success("‚úÖ Report generated successfully!")
                    
                except Exception as e:
                    st.error(f"‚ùå Report generation failed: {str(e)}")
    
    # Tab 3: Export Data
    with tab3:
        st.markdown("### üíæ Export Processed Data")
        st.markdown("Export your data in various formats after processing.")
        
        # Export Options
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### üìä Export Current Dataset")
            
            export_format = st.selectbox("Export Format:", ["CSV", "Excel", "JSON", "Parquet"])
            include_index = st.checkbox("Include Row Index", value=False)
            
            # Sample data for export
            if len(df) > 10000:
                export_sample = st.checkbox(f"Export Sample Only (dataset has {len(df):,} rows)", value=False)
                if export_sample:
                    sample_size = st.slider("Sample Size:", 1000, min(50000, len(df)), 10000)
                    export_df = df.sample(n=sample_size, random_state=42)
                    st.info(f"Will export {sample_size:,} randomly sampled rows")
                else:
                    export_df = df
            else:
                export_df = df
            
            # Generate export data
            if st.button("üíæ Generate Export File", key="export_data"):
                try:
                    if export_format == "CSV":
                        csv_data = export_df.to_csv(index=include_index)
                        st.download_button(
                            label="üì• Download CSV",
                            data=csv_data,
                            file_name=f"processed_data_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                            mime="text/csv"
                        )
                    
                    elif export_format == "JSON":
                        json_data = export_df.to_json(orient='records', indent=2)
                        st.download_button(
                            label="üì• Download JSON",
                            data=json_data,
                            file_name=f"processed_data_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.json",
                            mime="application/json"
                        )
                    
                    elif export_format == "Excel":
                        # Create Excel file in memory
                        from io import BytesIO
                        output = BytesIO()
                        with pd.ExcelWriter(output, engine='openpyxl') as writer:
                            export_df.to_excel(writer, sheet_name='Data', index=include_index)
                            
                            # Add summary sheet
                            summary_data = {
                                'Metric': ['Total Rows', 'Total Columns', 'Missing Values', 'Export Date'],
                                'Value': [
                                    len(export_df),
                                    len(export_df.columns),
                                    export_df.isnull().sum().sum(),
                                    pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')
                                ]
                            }
                            pd.DataFrame(summary_data).to_excel(writer, sheet_name='Summary', index=False)
                        
                        st.download_button(
                            label="üì• Download Excel",
                            data=output.getvalue(),
                            file_name=f"processed_data_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                    
                    elif export_format == "Parquet":
                        parquet_data = export_df.to_parquet(index=include_index)
                        st.download_button(
                            label="üì• Download Parquet",
                            data=parquet_data,
                            file_name=f"processed_data_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.parquet",
                            mime="application/octet-stream"
                        )
                    
                    st.success(f"‚úÖ {export_format} export file generated successfully!")
                    
                except Exception as e:
                    st.error(f"‚ùå Export failed: {str(e)}")
        
        with col2:
            st.markdown("#### üìà Export Analysis Results")
            
            # Export analysis results if available
            if hasattr(st.session_state, 'eda_results') and st.session_state.eda_results:
                if st.button("üìä Export EDA Results", key="export_eda"):
                    try:
                        import json
                        eda_json = json.dumps(st.session_state.eda_results, indent=2, default=str)
                        
                        st.download_button(
                            label="üì• Download EDA Results (JSON)",
                            data=eda_json,
                            file_name=f"eda_results_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.json",
                            mime="application/json"
                        )
                        
                        st.success("‚úÖ EDA results exported successfully!")
                    except Exception as e:
                        st.error(f"‚ùå EDA export failed: {str(e)}")
            else:
                st.info("No EDA results available. Run EDA analysis first!")
            
            # Export quality assessment if available
            if hasattr(st.session_state, 'quality_results') and st.session_state.quality_results:
                if st.button("üéØ Export Quality Assessment", key="export_quality"):
                    try:
                        import json
                        quality_json = json.dumps(st.session_state.quality_results, indent=2, default=str)
                        
                        st.download_button(
                            label="üì• Download Quality Assessment (JSON)",
                            data=quality_json,
                            file_name=f"quality_assessment_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.json",
                            mime="application/json"
                        )
                        
                        st.success("‚úÖ Quality assessment exported successfully!")
                    except Exception as e:
                        st.error(f"‚ùå Quality export failed: {str(e)}")
            else:
                st.info("No quality assessment available. Run AI insights first!")
    
    # Tab 4: Custom Reports
    with tab4:
        st.markdown("### üìà Custom Report Builder")
        st.markdown("Build custom reports with specific analyses and visualizations.")
        
        # Custom report builder
        with st.expander("üõ†Ô∏è Report Builder", expanded=True):
            custom_title = st.text_input("Custom Report Title:", value="Custom Analysis Report")
            
            # Select columns to analyze
            selected_columns = st.multiselect(
                "Select Columns to Include:",
                df.columns.tolist(),
                default=df.columns.tolist()[:5]  # Default to first 5 columns
            )
            
            if selected_columns:
                # Analysis options
                st.markdown("**Analysis Options:**")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    include_descriptive = st.checkbox("Descriptive Statistics", value=True)
                    include_missing = st.checkbox("Missing Value Analysis", value=True)
                    include_outliers = st.checkbox("Outlier Detection", value=True)
                
                with col2:
                    include_correlations = st.checkbox("Correlation Analysis", value=True)
                    include_distributions = st.checkbox("Distribution Analysis", value=True)
                    include_unique = st.checkbox("Unique Value Analysis", value=True)
                
                with col3:
                    include_plots = st.checkbox("Generate Plots", value=True)
                    include_insights = st.checkbox("AI Insights", value=True)
                    include_recommendations = st.checkbox("Recommendations", value=True)
                
                # Generate custom report
                if st.button("üöÄ Generate Custom Report", key="custom_report"):
                    with st.spinner("üîÑ Building custom report..."):
                        try:
                            custom_report_content = generate_custom_report(
                                df[selected_columns],
                                custom_title,
                                include_descriptive,
                                include_missing,
                                include_outliers,
                                include_correlations,
                                include_distributions,
                                include_unique,
                                include_plots,
                                include_insights,
                                include_recommendations
                            )
                            
                            st.markdown("### üìÑ Custom Report")
                            st.markdown(custom_report_content, unsafe_allow_html=True)
                            
                            # Download button
                            st.download_button(
                                label="üíæ Download Custom Report",
                                data=custom_report_content,
                                file_name=f"{custom_title.replace(' ', '_')}.html",
                                mime="text/html"
                            )
                            
                            st.success("‚úÖ Custom report generated successfully!")
                            
                        except Exception as e:
                            st.error(f"‚ùå Custom report generation failed: {str(e)}")
            else:
                st.warning("Please select at least one column to analyze.")


def generate_report_content(df, title, include_summary, include_statistics, include_visualizations, 
                          include_quality_assessment, include_recommendations, include_code, include_appendix):
    """Generate comprehensive report content"""
    
    html_content = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>{title}</title>
        <style>
            body {{ font-family: Arial, sans-serif; margin: 40px; }}
            h1 {{ color: #2E86AB; border-bottom: 2px solid #2E86AB; }}
            h2 {{ color: #A23B72; margin-top: 30px; }}
            h3 {{ color: #F18F01; }}
            .metric {{ background: #f0f0f0; padding: 10px; margin: 5px; border-radius: 5px; display: inline-block; }}
            .section {{ margin: 20px 0; }}
            table {{ border-collapse: collapse; width: 100%; }}
            th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
            th {{ background-color: #f2f2f2; }}
            .warning {{ background: #fff3cd; border: 1px solid #ffeaa7; padding: 10px; border-radius: 5px; }}
            .success {{ background: #d4edda; border: 1px solid #c3e6cb; padding: 10px; border-radius: 5px; }}
        </style>
    </head>
    <body>
        <h1>{title}</h1>
        <p><strong>Generated on:</strong> {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        <p><strong>Dataset:</strong> {len(df)} rows √ó {len(df.columns)} columns</p>
    """
    
    if include_summary:
        html_content += f"""
        <div class="section">
            <h2>üìä Dataset Summary</h2>
            <div class="metric">Total Rows: {len(df):,}</div>
            <div class="metric">Total Columns: {len(df.columns)}</div>
            <div class="metric">Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB</div>
            <div class="metric">Missing Values: {(df.isnull().sum().sum() / df.size * 100):.1f}%</div>
            
            <h3>Column Information</h3>
            <table>
                <tr><th>Column</th><th>Type</th><th>Non-Null</th><th>Missing</th><th>Missing %</th></tr>
        """
        
        for col in df.columns:
            non_null = df[col].count()
            missing = df[col].isnull().sum()
            missing_pct = (missing / len(df)) * 100
            html_content += f"""
                <tr>
                    <td>{col}</td>
                    <td>{str(df[col].dtype)}</td>
                    <td>{non_null:,}</td>
                    <td>{missing:,}</td>
                    <td>{missing_pct:.1f}%</td>
                </tr>
            """
        
        html_content += "</table></div>"
    
    if include_statistics:
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            html_content += """
            <div class="section">
                <h2>üìà Statistical Summary</h2>
                <h3>Numeric Columns</h3>
                <table>
                    <tr><th>Column</th><th>Mean</th><th>Std</th><th>Min</th><th>25%</th><th>50%</th><th>75%</th><th>Max</th></tr>
            """
            
            stats = df[numeric_cols].describe()
            for col in numeric_cols:
                html_content += f"""
                    <tr>
                        <td>{col}</td>
                        <td>{stats.loc['mean', col]:.2f}</td>
                        <td>{stats.loc['std', col]:.2f}</td>
                        <td>{stats.loc['min', col]:.2f}</td>
                        <td>{stats.loc['25%', col]:.2f}</td>
                        <td>{stats.loc['50%', col]:.2f}</td>
                        <td>{stats.loc['75%', col]:.2f}</td>
                        <td>{stats.loc['max', col]:.2f}</td>
                    </tr>
                """
            
            html_content += "</table></div>"
    
    if include_quality_assessment:
        missing_pct = (df.isnull().sum().sum() / df.size) * 100
        duplicates = df.duplicated().sum()
        
        html_content += f"""
        <div class="section">
            <h2>üéØ Data Quality Assessment</h2>
            <div class="{'success' if missing_pct < 5 else 'warning'}">
                <strong>Missing Data:</strong> {missing_pct:.1f}% of total values are missing
            </div>
            <div class="{'success' if duplicates == 0 else 'warning'}">
                <strong>Duplicate Rows:</strong> {duplicates:,} duplicate rows found
            </div>
        </div>
        """
    
    if include_recommendations:
        html_content += """
        <div class="section">
            <h2>üí° Recommendations</h2>
            <ul>
                <li>Consider handling missing values using appropriate imputation techniques</li>
                <li>Check for outliers in numeric columns and decide on treatment strategy</li>
                <li>Validate data types and convert if necessary</li>
                <li>Consider feature engineering for better model performance</li>
            </ul>
        </div>
        """
    
    if include_appendix:
        html_content += f"""
        <div class="section">
            <h2>üìã Technical Appendix</h2>
            <h3>Dataset Information</h3>
            <ul>
                <li><strong>Shape:</strong> {df.shape}</li>
                <li><strong>Memory Usage:</strong> {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB</li>
                <li><strong>Data Types:</strong> {df.dtypes.value_counts().to_dict()}</li>
            </ul>
        </div>
        """
    
    html_content += """
    </body>
    </html>
    """
    
    return html_content


def generate_custom_report(df, title, include_descriptive, include_missing, include_outliers,
                         include_correlations, include_distributions, include_unique,
                         include_plots, include_insights, include_recommendations):
    """Generate custom report content"""
    
    html_content = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>{title}</title>
        <style>
            body {{ font-family: Arial, sans-serif; margin: 40px; }}
            h1 {{ color: #2E86AB; border-bottom: 2px solid #2E86AB; }}
            h2 {{ color: #A23B72; margin-top: 30px; }}
            .metric {{ background: #f0f0f0; padding: 10px; margin: 5px; border-radius: 5px; display: inline-block; }}
            table {{ border-collapse: collapse; width: 100%; }}
            th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
            th {{ background-color: #f2f2f2; }}
        </style>
    </head>
    <body>
        <h1>{title}</h1>
        <p><strong>Generated on:</strong> {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        <p><strong>Selected Columns:</strong> {len(df.columns)} columns analyzed</p>
    """
    
    if include_descriptive:
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            html_content += """
            <h2>üìä Descriptive Statistics</h2>
            <table>
                <tr><th>Column</th><th>Count</th><th>Mean</th><th>Std</th><th>Min</th><th>Max</th></tr>
            """
            
            for col in numeric_cols:
                stats = df[col].describe()
                html_content += f"""
                    <tr>
                        <td>{col}</td>
                        <td>{stats['count']:.0f}</td>
                        <td>{stats['mean']:.2f}</td>
                        <td>{stats['std']:.2f}</td>
                        <td>{stats['min']:.2f}</td>
                        <td>{stats['max']:.2f}</td>
                    </tr>
                """
            
            html_content += "</table>"
    
    if include_missing:
        html_content += "<h2>‚ùì Missing Value Analysis</h2>"
        missing_data = df.isnull().sum()
        missing_cols = missing_data[missing_data > 0]
        
        if len(missing_cols) > 0:
            html_content += "<table><tr><th>Column</th><th>Missing Count</th><th>Missing %</th></tr>"
            for col, count in missing_cols.items():
                pct = (count / len(df)) * 100
                html_content += f"<tr><td>{col}</td><td>{count}</td><td>{pct:.1f}%</td></tr>"
            html_content += "</table>"
        else:
            html_content += "<p>‚úÖ No missing values found in selected columns.</p>"
    
    if include_unique:
        html_content += "<h2>üî¢ Unique Value Analysis</h2><table><tr><th>Column</th><th>Unique Values</th><th>Unique %</th></tr>"
        for col in df.columns:
            unique_count = df[col].nunique()
            unique_pct = (unique_count / len(df)) * 100
            html_content += f"<tr><td>{col}</td><td>{unique_count}</td><td>{unique_pct:.1f}%</td></tr>"
        html_content += "</table>"
    
    html_content += "</body></html>"
    
    return html_content


if __name__ == "__main__":
    main()